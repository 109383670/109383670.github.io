<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>一点乐趣</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://109383670.github.io/"/>
  <updated>2019-04-04T07:18:33.747Z</updated>
  <id>https://109383670.github.io/</id>
  
  <author>
    <name>BoomCode</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>绘画名家：博斯</title>
    <link href="https://109383670.github.io/2019/04/04/%E5%8D%9A%E6%96%AF/"/>
    <id>https://109383670.github.io/2019/04/04/博斯/</id>
    <published>2019-04-04T06:57:26.200Z</published>
    <updated>2019-04-04T07:18:33.747Z</updated>
    
    <content type="html"><![CDATA[<h2 id="姓名"><a href="#姓名" class="headerlink" title="姓名"></a>姓名</h2><p>希罗尼穆斯·博斯 (Hieronymus Bosch)。</p><h2 id="长相"><a href="#长相" class="headerlink" title="长相"></a>长相</h2><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Jheronimus_Bosch_%28cropped%29.jpg/220px-Jheronimus_Bosch_%28cropped%29.jpg" alt=" "></p><h2 id="国籍"><a href="#国籍" class="headerlink" title="国籍"></a>国籍</h2><p>::荷兰::</p><h2 id="在世时间"><a href="#在世时间" class="headerlink" title="在世时间"></a>在世时间</h2><p>::1450-1516::</p><h2 id="个人经历"><a href="#个人经历" class="headerlink" title="个人经历"></a>个人经历</h2><p>出生在艺术世家，祖父和父亲都是地方有名的画家，博斯本人也声名显赫。<br>他多数的画作多在描绘罪恶与人类道德的沉沦。博斯以恶魔、半人半兽甚至是机械的形象来表现人的邪恶。<br>他的图画复杂，有高度的原创性、想像力，并大量使用各式的象征与符号，其中有些甚至在他的时代中也非常晦涩难解。博斯被认为是20世纪的超现实主义的启发者之一。<br>他的真名是耶罗尼米斯（或“耶罗恩”）·范·阿肯（Jheronimus（或Jeroen） van Aken），意思是“亚琛来的人”。他在一部分画作上署名Bosch（荷兰文，音近英文Boss），取自他的出生地斯海尔托亨博斯。在西班牙文中他则多被称为El Bosco。<br>博斯出生于绘画世家，他的双亲分别是荷兰与德国人。他大部分的人生都在斯海尔托亨博斯渡过，这是十五世纪当时布拉班特（今荷兰南部）一个热闹的城市。1463年时，约13岁的他可能曾目睹在当地发生的严重火灾。不久之后他成为知名的画家，甚至曾接到海外的委托。1488年他加入了圣母兄弟会，一个极端保守的信仰组织，由40位斯海尔托亨博斯当地有权势的市民，以及欧洲各地7000多名的会员组成。</p><h2 id="有何特长"><a href="#有何特长" class="headerlink" title="有何特长"></a>有何特长</h2><p>他富有想象力的画作充满了荒唐的形式和怪异的象征主义。在被忽视了几个世纪后，他的原创性、讽刺的运用、及技法在今日已得到推崇。<br>博斯晚期的作品无论是构图和造型，还是色彩和笔触都具有新的创见和高深的造诣。博斯在美术史上历来被认为是个不可思议的画家，他那充满着奇思怪想的画面像迷一样难解，其实他所创造的艺术形象并非凭空臆造，而是为了表现自己强烈 的反封建思想。他从传统的哥特式雕塑中、中世纪动物故事插图、色彩抄本和中世纪的宝石古钱币中吸收有意思的形象，同时还借用占星术来间接表达自己的思想。他的艺术创造和影响是超越时空的，他被誉为-现代绘画的始祖。</p><h2 id="作品展示"><a href="#作品展示" class="headerlink" title="作品展示"></a>作品展示</h2><h3 id="《圣安东尼的诱惑》"><a href="#《圣安东尼的诱惑》" class="headerlink" title="《圣安东尼的诱惑》"></a>《圣安东尼的诱惑》</h3><p><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/75/37269.jpg" alt=" "><br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/113/56190.jpg" alt=" "><br>博斯的代表作品。圣安东尼是一位虔诚的基督教徒，在父母去世后，他将财产尽数分给穷人，自己隐居墓地，苦苦修行。其时经历了魔鬼的种种诱惑，从未动摇过他的坚定信念。<br>画家画了满幅离奇古怪的各种动物、人物、半人半兽的怪物，借以影射天主教会、教士的虚伪。圣安东尼跪在平台上举着一碗清水，而周围都沉浸在花天酒地的寻欢作乐中，在平台右下角，那个长着狐狸头、老鼠脸、长鼻上架着一付眼镜的伪君子，假正经地在阅读圣经；屋顶上那个教士正和一个女人饮酒作乐，旁边立着一位裸女。圣安东尼提倡人应绝欲，可是他周围的人却在拼命地追求各种欲念。这些都表现出教会的虚伪、可耻、可笑。</p><h3 id="《愚者之船》"><a href="#《愚者之船》" class="headerlink" title="《愚者之船》"></a>《愚者之船》</h3><p><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/75/37285.jpg" alt=" "><br>15世纪尼德兰的人文主义学者们，已经拿起笔揭露教会的腐败，曾创作有《 愚人船》和《愚蠢的颂赞》等讽刺性文学作品，对教士的贪婪淫荡、神学家的虚妄无知、封建统治者的不劳而获和愚蠢顽固进行尖锐的讽刺、揭露和抨击。<br>画中的“愚者”象征社会上各种罪恶行径，他们同乘一条船，由一个傻子驾驶着开往所谓“愚人的天堂”。船上一群荒淫无道者只顾吃喝弹唱，却不知傻子驾驶的船行将覆灭的警告。<br><a id="more"></a></p><h3 id="《干草车》"><a href="#《干草车》" class="headerlink" title="《干草车》"></a>《干草车》</h3><p><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/75/37254.jpg" alt=" "><br>希罗尼穆斯·波希是当时最有群众基础的一位画师。油画《干草车》也是波希的代表作之一。围绕这辆缓缓前进的干草车的是一些人兽混杂、荒诞怪异的艺术形象。这是一幅隐喻性与真实性相结合的寓言画。《干草车》这幅画是三叶祭坛画的中央一块，现藏西班牙马德里的普拉多美术馆。<br>《干草车》来自尼德兰一句古老的佛兰芒谚语：“世界是一个干草垛：人人在上为所欲为。”在波希的这幅油画中有天使与魔鬼接吻的情节；有弹曼陀铃的浪子坐在修女膝头调情的情节；干草垛的顶上既有怪物奏乐，也有圣女祈祷。干草车被几头奇怪的生物拖曳着。车后跟随着兴高采烈的教皇、国王与众百姓。有些人已跑在前头，有的则在车轮间东奔西窜，有的已被碾死在车轮下。人兽夹杂，尊卑交错。长着马脚的鱼张着大嘴，后面又有一只大老鼠，它的背上掮着古怪的树枝；有人要搬梯子爬上草垛去。车前几个人因互相倾轧而攀登不成，于是相互斗殴。有的把对方打倒在地，使劲扼住对方喉咙，欲置之死地而后快，然而干草车依然缓缓前进。这些渺小的生物气势汹汹，但也忙忙碌碌。构成荒诞古怪的艺术氛围，这象征人世间的什么，就不言而喻了。天空是一片蔚蓝。在干草车上空有一黄色祥云，里面钻出一个瘦小的基督。在画家波希眼里，这个世界就是这样可悲可笑，到处是光怪陆离。我们欣赏波希的画作，很难逐一破译这些怪诞人物和生物的生活“密码”。不过，这类画在于意会，图解性说明似无全然必要，艺术与生活事实上也不是对等的。这里所必须注意到的倒是《干草车》这幅画的用途，它是祭坛画。祭坛画上描绘这些晦涩的民间谚语题材，不能不使人感到惊讶。难道教会能容忍这种讽刺艺术吗？</p><h3 id="《人间欢乐园》"><a href="#《人间欢乐园》" class="headerlink" title="《人间欢乐园》"></a>《人间欢乐园》</h3><p><img src="https://upload.wikimedia.org/wikipedia/commons/6/6d/The_Garden_of_Earthly_Delights_by_Bosch_High_Resolution.jpg" alt="images"><br><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/75/37250.jpg" alt=" "><br>博斯制作了多幅三联画──绘在三片接合起来的木质屏风上的画作，其中最有名的是《人间乐园》（亦作《尘世乐园》）。这件三连画的左幅，描绘了乐园中的亚当与夏娃与众多奇妙的生物；中幅以大量裸身的人体、巨大的水果和鸟类描写人间的乐园；右幅则是地狱的情境，充斥着大量造型奇幻的狱卒，以各式怪异的酷刑逞罚罪人。三件画作合起时，观赏者可见上帝创造地球的灰色装饰画。<br>这些画作有一层较粗糙的颜料表层，与传统弗拉芒风格，以平滑的表面修饰人为的不自然的手法大异其趣。<br>到了晚年时，博斯的风格已有所转变，改以描绘大型、接近观赏者的人物为表现方式。代表作是《戴刺冠的基督》（Christ Crowned with Thorns）。<br>博斯从未在画作上注明日期，也仅在部分作品上签名（某些签名则被认为并非本人）；总括来说，目前确认出自博斯之手的画作，仅有25幅。西班牙国王腓力二世在博斯死后收藏了他的大部分作品，因此目前西班牙马德里的普拉多美术馆收藏了博斯最多的作品，包括《人间乐园》。<br>稍晚期的弗拉芒画家老彼得·布吕赫尔受博斯影响，其作品风格与博斯相当近似，如1562年之《死亡的胜利》。</p><h3 id="《死亡与守财奴》"><a href="#《死亡与守财奴》" class="headerlink" title="《死亡与守财奴》"></a>《死亡与守财奴》</h3><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/48/Jheronimus_Bosch_050.jpg/255px-Jheronimus_Bosch_050.jpg" alt=" "></p><h3 id="《最后的审判》"><a href="#《最后的审判》" class="headerlink" title="《最后的审判》"></a>《最后的审判》</h3><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Last_judgement_Bosch.jpg/1024px-Last_judgement_Bosch.jpg" alt=" "></p><h3 id="《七宗罪》"><a href="#《七宗罪》" class="headerlink" title="《七宗罪》"></a>《七宗罪》</h3><p><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/75/37283.jpg" alt=" "></p><h3 id="《戴荆冠的基督》"><a href="#《戴荆冠的基督》" class="headerlink" title="《戴荆冠的基督》"></a>《戴荆冠的基督》</h3><p><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/94/46975.jpg" alt=" "><br>希罗尼穆斯·波希的这件作品《戴荆冠的基督》描绘的是基督被罗马巡抚彼拉多判处死刑之后，看守他的兵丁们为了侮辱他，讽刺他是犹太王，又用荆棘做了一顶荆冠戴在他头上，“恭喜”他为王。<br>油画中左边的看守正在往基督头上戴荆棘环，右边扶着基督的肩膀，一脸的得意之状。左下角的一个则是嬉皮笑脸，右下角的看守抓住基督的衣服扮下跪之状，引得旁边人的嬉笑。而基督则是一脸的安详。作者通过夸张的写法，把看守戏弄，侮辱基督的场景展现得淋漓尽致。充分展现出作者深厚功底以及对场景及人物表情的捕捉能力。</p><h3 id="《治疗愚蠢》"><a href="#《治疗愚蠢》" class="headerlink" title="《治疗愚蠢》"></a>《治疗愚蠢》</h3><p><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/75/37277.jpg" alt=" "></p><h3 id="《天堂与地狱》"><a href="#《天堂与地狱》" class="headerlink" title="《天堂与地狱》"></a>《天堂与地狱》</h3><p>!{<a href="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/75/37262.jpg" target="_blank" rel="noopener"> </a></p><h3 id="《人生之路》"><a href="#《人生之路》" class="headerlink" title="《人生之路》"></a>《人生之路》</h3><p><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/75/37282.jpg" alt=" "></p><h3 id="《人之树》"><a href="#《人之树》" class="headerlink" title="《人之树》"></a>《人之树》</h3><p><img src="http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/75/37281.jpg" alt=" "></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;姓名&quot;&gt;&lt;a href=&quot;#姓名&quot; class=&quot;headerlink&quot; title=&quot;姓名&quot;&gt;&lt;/a&gt;姓名&lt;/h2&gt;&lt;p&gt;希罗尼穆斯·博斯 (Hieronymus Bosch)。&lt;/p&gt;
&lt;h2 id=&quot;长相&quot;&gt;&lt;a href=&quot;#长相&quot; class=&quot;headerlink&quot; title=&quot;长相&quot;&gt;&lt;/a&gt;长相&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Jheronimus_Bosch_%28cropped%29.jpg/220px-Jheronimus_Bosch_%28cropped%29.jpg&quot; alt=&quot; &quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;国籍&quot;&gt;&lt;a href=&quot;#国籍&quot; class=&quot;headerlink&quot; title=&quot;国籍&quot;&gt;&lt;/a&gt;国籍&lt;/h2&gt;&lt;p&gt;::荷兰::&lt;/p&gt;
&lt;h2 id=&quot;在世时间&quot;&gt;&lt;a href=&quot;#在世时间&quot; class=&quot;headerlink&quot; title=&quot;在世时间&quot;&gt;&lt;/a&gt;在世时间&lt;/h2&gt;&lt;p&gt;::1450-1516::&lt;/p&gt;
&lt;h2 id=&quot;个人经历&quot;&gt;&lt;a href=&quot;#个人经历&quot; class=&quot;headerlink&quot; title=&quot;个人经历&quot;&gt;&lt;/a&gt;个人经历&lt;/h2&gt;&lt;p&gt;出生在艺术世家，祖父和父亲都是地方有名的画家，博斯本人也声名显赫。&lt;br&gt;他多数的画作多在描绘罪恶与人类道德的沉沦。博斯以恶魔、半人半兽甚至是机械的形象来表现人的邪恶。&lt;br&gt;他的图画复杂，有高度的原创性、想像力，并大量使用各式的象征与符号，其中有些甚至在他的时代中也非常晦涩难解。博斯被认为是20世纪的超现实主义的启发者之一。&lt;br&gt;他的真名是耶罗尼米斯（或“耶罗恩”）·范·阿肯（Jheronimus（或Jeroen） van Aken），意思是“亚琛来的人”。他在一部分画作上署名Bosch（荷兰文，音近英文Boss），取自他的出生地斯海尔托亨博斯。在西班牙文中他则多被称为El Bosco。&lt;br&gt;博斯出生于绘画世家，他的双亲分别是荷兰与德国人。他大部分的人生都在斯海尔托亨博斯渡过，这是十五世纪当时布拉班特（今荷兰南部）一个热闹的城市。1463年时，约13岁的他可能曾目睹在当地发生的严重火灾。不久之后他成为知名的画家，甚至曾接到海外的委托。1488年他加入了圣母兄弟会，一个极端保守的信仰组织，由40位斯海尔托亨博斯当地有权势的市民，以及欧洲各地7000多名的会员组成。&lt;/p&gt;
&lt;h2 id=&quot;有何特长&quot;&gt;&lt;a href=&quot;#有何特长&quot; class=&quot;headerlink&quot; title=&quot;有何特长&quot;&gt;&lt;/a&gt;有何特长&lt;/h2&gt;&lt;p&gt;他富有想象力的画作充满了荒唐的形式和怪异的象征主义。在被忽视了几个世纪后，他的原创性、讽刺的运用、及技法在今日已得到推崇。&lt;br&gt;博斯晚期的作品无论是构图和造型，还是色彩和笔触都具有新的创见和高深的造诣。博斯在美术史上历来被认为是个不可思议的画家，他那充满着奇思怪想的画面像迷一样难解，其实他所创造的艺术形象并非凭空臆造，而是为了表现自己强烈 的反封建思想。他从传统的哥特式雕塑中、中世纪动物故事插图、色彩抄本和中世纪的宝石古钱币中吸收有意思的形象，同时还借用占星术来间接表达自己的思想。他的艺术创造和影响是超越时空的，他被誉为-现代绘画的始祖。&lt;/p&gt;
&lt;h2 id=&quot;作品展示&quot;&gt;&lt;a href=&quot;#作品展示&quot; class=&quot;headerlink&quot; title=&quot;作品展示&quot;&gt;&lt;/a&gt;作品展示&lt;/h2&gt;&lt;h3 id=&quot;《圣安东尼的诱惑》&quot;&gt;&lt;a href=&quot;#《圣安东尼的诱惑》&quot; class=&quot;headerlink&quot; title=&quot;《圣安东尼的诱惑》&quot;&gt;&lt;/a&gt;《圣安东尼的诱惑》&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/75/37269.jpg&quot; alt=&quot; &quot;&gt;&lt;br&gt;&lt;img src=&quot;http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/113/56190.jpg&quot; alt=&quot; &quot;&gt;&lt;br&gt;博斯的代表作品。圣安东尼是一位虔诚的基督教徒，在父母去世后，他将财产尽数分给穷人，自己隐居墓地，苦苦修行。其时经历了魔鬼的种种诱惑，从未动摇过他的坚定信念。&lt;br&gt;画家画了满幅离奇古怪的各种动物、人物、半人半兽的怪物，借以影射天主教会、教士的虚伪。圣安东尼跪在平台上举着一碗清水，而周围都沉浸在花天酒地的寻欢作乐中，在平台右下角，那个长着狐狸头、老鼠脸、长鼻上架着一付眼镜的伪君子，假正经地在阅读圣经；屋顶上那个教士正和一个女人饮酒作乐，旁边立着一位裸女。圣安东尼提倡人应绝欲，可是他周围的人却在拼命地追求各种欲念。这些都表现出教会的虚伪、可耻、可笑。&lt;/p&gt;
&lt;h3 id=&quot;《愚者之船》&quot;&gt;&lt;a href=&quot;#《愚者之船》&quot; class=&quot;headerlink&quot; title=&quot;《愚者之船》&quot;&gt;&lt;/a&gt;《愚者之船》&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://www.youhuaaa.com/UploadFiles/images/Painting_Pic_Big/75/37285.jpg&quot; alt=&quot; &quot;&gt;&lt;br&gt;15世纪尼德兰的人文主义学者们，已经拿起笔揭露教会的腐败，曾创作有《 愚人船》和《愚蠢的颂赞》等讽刺性文学作品，对教士的贪婪淫荡、神学家的虚妄无知、封建统治者的不劳而获和愚蠢顽固进行尖锐的讽刺、揭露和抨击。&lt;br&gt;画中的“愚者”象征社会上各种罪恶行径，他们同乘一条船，由一个傻子驾驶着开往所谓“愚人的天堂”。船上一群荒淫无道者只顾吃喝弹唱，却不知傻子驾驶的船行将覆灭的警告。&lt;br&gt;
    
    </summary>
    
    
      <category term="美术名家" scheme="https://109383670.github.io/tags/%E7%BE%8E%E6%9C%AF%E5%90%8D%E5%AE%B6/"/>
    
      <category term="博斯" scheme="https://109383670.github.io/tags/%E5%8D%9A%E6%96%AF/"/>
    
  </entry>
  
  <entry>
    <title>种子批量转磁链</title>
    <link href="https://109383670.github.io/2019/04/03/%E7%A7%8D%E5%AD%90%E6%89%B9%E9%87%8F%E8%BD%AC%E7%A3%81%E9%93%BE/"/>
    <id>https://109383670.github.io/2019/04/03/种子批量转磁链/</id>
    <published>2019-04-03T10:19:56.731Z</published>
    <updated>2019-04-03T10:45:35.025Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Torrent"><a href="#Torrent" class="headerlink" title="Torrent"></a>Torrent</h2><h3 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h3><p>该技术由美国的程序员布莱姆·科亨于2001年4月时发布，并于2001年7月2日时首次正式应用。</p><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>普通的HTTP／FTP下载使用TCP/IP协议，BitTorrent协议是架构于TCP/IP协议之上的一个P2P文件传输通信协议，处于TCP/IP结构的应用层。<br>根据BitTorrent协议，文件发布者会根据要发布的文件生成提供一个.torrent文件，即种子文件，也简称为“种子”。</p><h4 id="组成"><a href="#组成" class="headerlink" title="组成"></a>组成</h4><p>种子文件本质是文本文件，包括Tracker和文件信息两个部分：<br>Tracker服务器保存所有正在下载文件的客户端的地址，有人新建连接时，会将地址反馈给新的连接。<br>文件信息是用Bencode进行编码，是要下载的文件的索引。</p><h5 id="Tracker信息"><a href="#Tracker信息" class="headerlink" title="Tracker信息"></a>Tracker信息</h5><pre><code>* Tracker服务器地址* Tracker服务器设置</code></pre><h5 id="文件信息"><a href="#文件信息" class="headerlink" title="文件信息"></a>文件信息</h5><ul><li>announce - tracker的URL</li><li>info - 该条映射到一个字典，该字典的键将取决于共享的一个或多个文件<ul><li>name - 建议保存到的文件和目录名称</li><li>piece length - 每个文件块的字节数。通常为256KB = 262144B</li><li>pieces - 每个文件块的SHA-1的集成Hash。因为SHA-1会返回160-bit的Hash，所以pieces将会得到1个160-bit的整数倍的字符串。和一个length（相当于只有一个文件正在共享）或files（相当于当多个文件被共享）：</li><li>length - 文件的大小（以字节为单位）</li><li>files - 一个字典的列表（每个字典对应一个文件）与以下的键<ul><li>path - 一个对应子目录名的字符串列表，最后一项是实际的文件名称</li><li>length - 文件的大小（以字节为单位）</li></ul></li></ul></li></ul><p>info-hash:每一个种子唯一的编码，由info字段的数据计算而成。</p><h4 id="DHT网络"><a href="#DHT网络" class="headerlink" title="DHT网络"></a>DHT网络</h4><p>DHT全称为分布式哈希表（Distributed Hash Table），是一种分布式存储方法。在不需要服务器的情况下，每个客户端负责一个小范围的路由，并负责存储一小部分数据，从而实现整个DHT网络的寻址和存储。<br> <a id="more"></a></p><h2 id="磁链"><a href="#磁链" class="headerlink" title="磁链"></a>磁链</h2><h3 id="历史-1"><a href="#历史-1" class="headerlink" title="历史"></a>历史</h3><p>这个标准的草稿出现于2002年，是为了对eDonkey2000的“ed2k:”和Freenet的“freenet:”两个URI格式进行“厂商与项目中立化”（vendor- and project-neutral generalization）而制定的。同时这个标准也尝试紧密地跟进IETF官方的URI标准。</p><h3 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h3><p>特点：</p><ul><li>分布式。</li><li>不依赖于ip地址</li><li>没有中心服务器</li><li>开源<h3 id="组成-1"><a href="#组成-1" class="headerlink" title="组成"></a>组成</h3>磁力链接由一组参数组成，参数间的顺序没有讲究，其格式与在HTTP链接末尾的查询字符串相同。最常见的参数是”xt”，是”exact topic”的缩写，通常是一个特定文件的内容散列函数值形成的URN。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">magnet:?xt=urn:sha1:YNCKHTQCWBTRNJIV4WNAE52SJUQCZO5C</span><br></pre></td></tr></table></figure></li></ul><p>其值是Base32编码的文件的SHA-1散列。</p><p>基本描述<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">magnet:? xl = [字节大小]&amp; dn = [文件名（已编码URL）]&amp; xt = urn: tree: tiger: [ TTH <span class="built_in">hash</span>（Base32）]</span><br></pre></td></tr></table></figure></p><p>由参数来指定相关的内容：</p><ul><li>dn（显示名称）- 文件名</li><li>xl（绝对长度）- 文件字节数</li><li>xt（eXact Topic）- 包含文件散列函数值的URN。磁力链接的这部分最重要。用于寻找和验证包含着磁力链接中的文件。</li><li>as（可接受来源） - 在线文件的网络链接</li><li>xs（绝对资源）- P2P链接</li><li>kt（关键字）- 用于搜索的关键字</li><li>mt（文件列表）- 链接到一个包含磁力链接的元文件 (MAGMA - MAGnet MAnifest）</li><li>tr（Tracker地址）- BT下载的Tracker URL<h2 id="开发工具和平台"><a href="#开发工具和平台" class="headerlink" title="开发工具和平台"></a>开发工具和平台</h2></li></ul><h3 id="计算提取info-hash"><a href="#计算提取info-hash" class="headerlink" title="计算提取info_hash"></a>计算提取info_hash</h3><p>关键：info字段的值，必须先解码，再对info字段的值编码，然后才计算hash。直接从文件中删除其他部分行不通。</p><h3 id="js"><a href="#js" class="headerlink" title="js"></a>js</h3><h4 id="bencode库"><a href="#bencode库" class="headerlink" title="bencode库"></a>bencode库</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install bencode</span><br></pre></td></tr></table></figure><p>如果装了nvm,则-g全局安装会装在.nvm文件夹下。否则，就装在用户目录的node_module下。</p><h4 id="sha-1库"><a href="#sha-1库" class="headerlink" title="sha-1库"></a>sha-1库</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install js-sha1</span><br></pre></td></tr></table></figure><h4 id="实现代码"><a href="#实现代码" class="headerlink" title="实现代码"></a>实现代码</h4><h5 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h5><p>提取的磁力链接存放在种子目录下名为magnets.txt的文件中。</p><h5 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node t2m.js &lt;种子文件夹路径&gt;</span><br></pre></td></tr></table></figure><h5 id="js代码"><a href="#js代码" class="headerlink" title="js代码"></a>js代码</h5><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> fs = <span class="built_in">require</span>(<span class="string">"fs"</span>);</span><br><span class="line"><span class="keyword">var</span> bencode = <span class="built_in">require</span>(<span class="string">'bencode'</span>);</span><br><span class="line"><span class="keyword">var</span> sha1 = <span class="built_in">require</span>(<span class="string">'js-sha1'</span>);</span><br><span class="line"><span class="keyword">var</span> <span class="built_in">arguments</span> = process.argv.splice(<span class="number">2</span>); <span class="comment">//获取命令行参数，第三个元素是带的参数</span></span><br><span class="line"></span><br><span class="line">outMagnets(getMagnets(<span class="built_in">arguments</span>), <span class="built_in">arguments</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取磁链链接，arguments为文件夹路径</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getMagnets</span>(<span class="params">arguments</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> fileslist = fs.readdirSync(<span class="built_in">arguments</span>.toString());</span><br><span class="line">    <span class="keyword">var</span> magnetlist = <span class="keyword">new</span> <span class="built_in">Array</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">var</span> f <span class="keyword">in</span> fileslist) &#123;</span><br><span class="line">        <span class="keyword">var</span> torrentfile = <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">var</span> filename = fileslist[f].toString();</span><br><span class="line">        <span class="keyword">if</span> (filename.includes(<span class="string">".torrent"</span>)) &#123;</span><br><span class="line">            <span class="keyword">var</span> filepath = <span class="built_in">arguments</span>.toString() + <span class="string">'/'</span> + filename;</span><br><span class="line">            <span class="keyword">var</span> magnet = getInfoHash(filepath);</span><br><span class="line">            <span class="keyword">if</span> (magnet) &#123;</span><br><span class="line">                magnetlist.push(magnet);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//console.log(magnet);</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> magnetlist;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将结果输出为txt</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">outMagnets</span>(<span class="params">magnets, path</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (magnets.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">var</span> writebuffer = Buffer.from(arrayToString(magnets, <span class="string">'\n'</span>));</span><br><span class="line">        <span class="keyword">var</span> savepath = path.toString() + <span class="string">'/'</span> + <span class="string">"magnets.txt"</span>;</span><br><span class="line">        <span class="keyword">var</span> writesteam = fs.createWriteStream(savepath);</span><br><span class="line">        writesteam.write(writebuffer, <span class="string">'utf-8'</span>);</span><br><span class="line">        writesteam.end();</span><br><span class="line">        writesteam.on(<span class="string">'finish'</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">            <span class="built_in">console</span>.log(<span class="string">"写入完成"</span>);</span><br><span class="line">        &#125;);</span><br><span class="line">        writesteam.on(<span class="string">'error'</span>, <span class="function"><span class="keyword">function</span> (<span class="params">err</span>) </span>&#123;</span><br><span class="line">            <span class="built_in">console</span>.log(err);</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// buffer只能输出字符，所以必须将字符数组转换为字符形式，seq为分隔符</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">arrayToString</span>(<span class="params">arr, seq</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> str_value = <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">for</span> (a <span class="keyword">of</span> arr) &#123;</span><br><span class="line">        <span class="keyword">var</span> astr = a.toString();</span><br><span class="line">        <span class="keyword">if</span> (str_value) &#123;</span><br><span class="line">            str_value = str_value + seq + astr;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            str_value = astr;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> str_value;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 获取种子文件的info_hash值，有一个解密，再加密的过程</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getInfoHash</span>(<span class="params">torrentfile</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> result = bencode.decode(fs.readFileSync(torrentfile));</span><br><span class="line">    <span class="keyword">if</span> (result) &#123;</span><br><span class="line">        <span class="keyword">var</span> info = result[<span class="string">'info'</span>]; <span class="comment">//info 字典</span></span><br><span class="line">        <span class="keyword">var</span> info_hash = sha1(bencode.encode(info));</span><br><span class="line">        <span class="keyword">var</span> magnet = <span class="string">"magnet:?xt=urn:btih:"</span> + info_hash.toString();</span><br><span class="line">        <span class="keyword">return</span> magnet;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="python"><a href="#python" class="headerlink" title="python"></a>python</h3><h4 id="bencode库-1"><a href="#bencode库-1" class="headerlink" title="bencode库"></a>bencode库</h4><p><a href="https://github.com/bashkirtsevich-llc/py3bencode" target="_blank" rel="noopener">gittub</a><br>安装：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install py3-bencode</span><br></pre></td></tr></table></figure></p><h4 id="实现代码-1"><a href="#实现代码-1" class="headerlink" title="实现代码"></a>实现代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bencode <span class="keyword">import</span> bencode, bdecode</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> BytesIO</span><br><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"></span><br><span class="line">objTorrentFile = open(<span class="string">"test.torrent"</span>, <span class="string">"rb"</span>)</span><br><span class="line">decodedDict = bdecode(objTorrentFile.read())</span><br><span class="line"></span><br><span class="line">info_hash = hashlib.sha1(bencode(decodedDict[<span class="string">"info"</span>])).hexdigest()</span><br><span class="line">print(info_hash)</span><br></pre></td></tr></table></figure><p>在解码提取出info后，似乎还需要编码后，再求hash值</p><h2 id="参考网址"><a href="#参考网址" class="headerlink" title="参考网址"></a>参考网址</h2><p><a href="https://zh.wikipedia.org/wiki/磁力链接" target="_blank" rel="noopener">磁力链接wiki</a><br><a href="https://blog.csdn.net/xxxxxx91116/article/details/7971134" target="_blank" rel="noopener">磁力链接转换为种子文件</a><br><a href="http://www.bittorrent.org/beps/bep_0003.html" target="_blank" rel="noopener">官方种子格式说明</a><br><a href="https://blog.csdn.net/csupengu/article/details/8673666" target="_blank" rel="noopener">种子格式详解</a><br><a href="https://blog.csdn.net/u011412619/article/details/42002929" target="_blank" rel="noopener">bencode详解</a><br><a href="https://www.cnblogs.com/xiandedanteng/p/9006938.html" target="_blank" rel="noopener">python bencode可用</a><br><a href="https://github.com/bashkirtsevich-llc/py3bencode" target="_blank" rel="noopener">bencode-gitthub</a><br><a href="http://www.cnblogs.com/xiandedanteng/p/9014251.html" target="_blank" rel="noopener">bencode源码</a><br><a href="http://demon.tw/my-work/javascript-bencode.html" target="_blank" rel="noopener">js-bencode 实现</a><br><a href="https://en.wikipedia.org/wiki/Bencode" target="_blank" rel="noopener">wiki-bencode</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Torrent&quot;&gt;&lt;a href=&quot;#Torrent&quot; class=&quot;headerlink&quot; title=&quot;Torrent&quot;&gt;&lt;/a&gt;Torrent&lt;/h2&gt;&lt;h3 id=&quot;历史&quot;&gt;&lt;a href=&quot;#历史&quot; class=&quot;headerlink&quot; title=&quot;历史&quot;&gt;&lt;/a&gt;历史&lt;/h3&gt;&lt;p&gt;该技术由美国的程序员布莱姆·科亨于2001年4月时发布，并于2001年7月2日时首次正式应用。&lt;/p&gt;
&lt;h3 id=&quot;原理&quot;&gt;&lt;a href=&quot;#原理&quot; class=&quot;headerlink&quot; title=&quot;原理&quot;&gt;&lt;/a&gt;原理&lt;/h3&gt;&lt;p&gt;普通的HTTP／FTP下载使用TCP/IP协议，BitTorrent协议是架构于TCP/IP协议之上的一个P2P文件传输通信协议，处于TCP/IP结构的应用层。&lt;br&gt;根据BitTorrent协议，文件发布者会根据要发布的文件生成提供一个.torrent文件，即种子文件，也简称为“种子”。&lt;/p&gt;
&lt;h4 id=&quot;组成&quot;&gt;&lt;a href=&quot;#组成&quot; class=&quot;headerlink&quot; title=&quot;组成&quot;&gt;&lt;/a&gt;组成&lt;/h4&gt;&lt;p&gt;种子文件本质是文本文件，包括Tracker和文件信息两个部分：&lt;br&gt;Tracker服务器保存所有正在下载文件的客户端的地址，有人新建连接时，会将地址反馈给新的连接。&lt;br&gt;文件信息是用Bencode进行编码，是要下载的文件的索引。&lt;/p&gt;
&lt;h5 id=&quot;Tracker信息&quot;&gt;&lt;a href=&quot;#Tracker信息&quot; class=&quot;headerlink&quot; title=&quot;Tracker信息&quot;&gt;&lt;/a&gt;Tracker信息&lt;/h5&gt;&lt;pre&gt;&lt;code&gt;* Tracker服务器地址
* Tracker服务器设置
&lt;/code&gt;&lt;/pre&gt;&lt;h5 id=&quot;文件信息&quot;&gt;&lt;a href=&quot;#文件信息&quot; class=&quot;headerlink&quot; title=&quot;文件信息&quot;&gt;&lt;/a&gt;文件信息&lt;/h5&gt;&lt;ul&gt;
&lt;li&gt;announce - tracker的URL&lt;/li&gt;
&lt;li&gt;info - 该条映射到一个字典，该字典的键将取决于共享的一个或多个文件&lt;ul&gt;
&lt;li&gt;name - 建议保存到的文件和目录名称&lt;/li&gt;
&lt;li&gt;piece length - 每个文件块的字节数。通常为256KB = 262144B&lt;/li&gt;
&lt;li&gt;pieces - 每个文件块的SHA-1的集成Hash。因为SHA-1会返回160-bit的Hash，所以pieces将会得到1个160-bit的整数倍的字符串。和一个length（相当于只有一个文件正在共享）或files（相当于当多个文件被共享）：&lt;/li&gt;
&lt;li&gt;length - 文件的大小（以字节为单位）&lt;/li&gt;
&lt;li&gt;files - 一个字典的列表（每个字典对应一个文件）与以下的键&lt;ul&gt;
&lt;li&gt;path - 一个对应子目录名的字符串列表，最后一项是实际的文件名称&lt;/li&gt;
&lt;li&gt;length - 文件的大小（以字节为单位）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;info-hash:每一个种子唯一的编码，由info字段的数据计算而成。&lt;/p&gt;
&lt;h4 id=&quot;DHT网络&quot;&gt;&lt;a href=&quot;#DHT网络&quot; class=&quot;headerlink&quot; title=&quot;DHT网络&quot;&gt;&lt;/a&gt;DHT网络&lt;/h4&gt;&lt;p&gt;DHT全称为分布式哈希表（Distributed Hash Table），是一种分布式存储方法。在不需要服务器的情况下，每个客户端负责一个小范围的路由，并负责存储一小部分数据，从而实现整个DHT网络的寻址和存储。&lt;br&gt;
    
    </summary>
    
    
      <category term="javascript" scheme="https://109383670.github.io/tags/javascript/"/>
    
      <category term="小工具" scheme="https://109383670.github.io/tags/%E5%B0%8F%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>iOS开发常见问题</title>
    <link href="https://109383670.github.io/2019/03/09/iOS%20%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <id>https://109383670.github.io/2019/03/09/iOS 开发常见问题/</id>
    <published>2019-03-09T06:09:01.636Z</published>
    <updated>2019-03-09T06:18:03.574Z</updated>
    
    <content type="html"><![CDATA[<h2 id="隐私政策问题"><a href="#隐私政策问题" class="headerlink" title="隐私政策问题"></a>隐私政策问题</h2><p>从2018年10月3号起，所有新提交的App都必须提供隐私条例。<a href="https://developer.apple.com/news/?id=08312018a" target="_blank" rel="noopener">官方链接</a><br>可以利用网站在线生成，并且都提供在线页面。不过没有中文版本。部分条款要收费，不过free 版本的就足够用了。<br>提供在线生成的网站：<br><a href="https://www.freeprivacypolicy.com" target="_blank" rel="noopener">freeprivacypolicy</a><br><a href="https://privacypolicies.com" target="_blank" rel="noopener">privacypolicies</a></p><h2 id="视频预览问题"><a href="#视频预览问题" class="headerlink" title="视频预览问题"></a>视频预览问题</h2><p>对于竖屏的视频，mac自带的iMovies无法处理，必须用cut final pro来进行处理。<br>导出视频的格式如下：<br><a href="https://help.apple.com/app-store-connect/?lang=zh-cn#/dev4e413fcb8" target="_blank" rel="noopener">App 预览规范</a><br><a href="https://help.apple.com/app-store-connect/?lang=zh-cn#/devd274dd925" target="_blank" rel="noopener">屏幕快照规范</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;隐私政策问题&quot;&gt;&lt;a href=&quot;#隐私政策问题&quot; class=&quot;headerlink&quot; title=&quot;隐私政策问题&quot;&gt;&lt;/a&gt;隐私政策问题&lt;/h2&gt;&lt;p&gt;从2018年10月3号起，所有新提交的App都必须提供隐私条例。&lt;a href=&quot;https://devel
      
    
    </summary>
    
    
      <category term="iOS 开发" scheme="https://109383670.github.io/tags/iOS-%E5%BC%80%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>cocos2d-x 3.0相对于2.0的变化</title>
    <link href="https://109383670.github.io/2019/03/02/cocos2d-x%203.0%E7%9B%B8%E5%AF%B9%E4%BA%8E2.0%E7%9A%84%E5%8F%98%E5%8C%96/"/>
    <id>https://109383670.github.io/2019/03/02/cocos2d-x 3.0相对于2.0的变化/</id>
    <published>2019-03-02T07:44:18.102Z</published>
    <updated>2019-03-04T15:52:07.389Z</updated>
    
    <content type="html"><![CDATA[<h3 id="更新步骤"><a href="#更新步骤" class="headerlink" title="更新步骤"></a>更新步骤</h3><ol><li>下载开发包（github也可以)。</li><li>运行build目录下，cocos2d_tests.xcodeproj工程。</li><li>将编译Target选择成cpp-tests iOS。</li><li>运行。</li><li>用命令行命令生成一个模板工程：<br><code>cocos new MyGame -p com.MyCompany.MyGame -l cpp -d ~/MyCompany</code><br>将2.0代码加入模板工程中。如果是3.0升级就用模板工程中的cocos2d代替老版本的文件夹。</li></ol><h3 id="CClog-变成CCLOG"><a href="#CClog-变成CCLOG" class="headerlink" title="CClog 变成CCLOG"></a>CClog 变成CCLOG</h3><h3 id="CCArray-变成Array-CCSet等也变成set"><a href="#CCArray-变成Array-CCSet等也变成set" class="headerlink" title="CCArray 变成Array, CCSet等也变成set"></a>CCArray 变成<strong>Array, CCSet等也变成</strong>set</h3><h3 id="CCLayer中setTouchEnabled无效"><a href="#CCLayer中setTouchEnabled无效" class="headerlink" title="CCLayer中setTouchEnabled无效"></a>CCLayer中setTouchEnabled无效</h3><p>添加触摸事件器后，自动生效。</p><h3 id="ccTouchBegan等改成onTouchesBegan"><a href="#ccTouchBegan等改成onTouchesBegan" class="headerlink" title="ccTouchBegan等改成onTouchesBegan"></a>ccTouchBegan等改成onTouchesBegan</h3><p>触摸事件代码<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">auto</span> listener = EventListenerTouchAllAtOnce::create();</span><br><span class="line">listener-&gt;onTouchesBegan = CC_CALLBACK_2(ForceTouchTest::onTouchesBegan, <span class="keyword">this</span>);</span><br><span class="line">listener-&gt;onTouchesMoved = CC_CALLBACK_2(ForceTouchTest::onTouchesMoved, <span class="keyword">this</span>);</span><br><span class="line">listener-&gt;onTouchesEnded = CC_CALLBACK_2(ForceTouchTest::onTouchesEnded, <span class="keyword">this</span>);</span><br><span class="line">_eventDispatcher-&gt;addEventListenerWithSceneGraphPriority(listener, <span class="keyword">this</span>);</span><br></pre></td></tr></table></figure></p><h3 id="CCObject改成Ref"><a href="#CCObject改成Ref" class="headerlink" title="CCObject改成Ref"></a>CCObject改成Ref</h3><h3 id="CCPoint改成Vec2"><a href="#CCPoint改成Vec2" class="headerlink" title="CCPoint改成Vec2"></a>CCPoint改成Vec2</h3><h3 id="CCJumpTO等动作改成JumpTo"><a href="#CCJumpTO等动作改成JumpTo" class="headerlink" title="CCJumpTO等动作改成JumpTo"></a>CCJumpTO等动作改成JumpTo</h3><h3 id="CCPointZero改成Vec2-Zero"><a href="#CCPointZero改成Vec2-Zero" class="headerlink" title="CCPointZero改成Vec2::Zero"></a>CCPointZero改成Vec2::Zero</h3><p>除了0向量外，还有很多的静态值。</p><h3 id="动作回调CallFuncN有改动"><a href="#动作回调CallFuncN有改动" class="headerlink" title="动作回调CallFuncN有改动"></a>动作回调CallFuncN有改动</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ac_go =  Sequence::create(ac_p, ac_s, ac_s1,</span><br><span class="line">CallFuncN::create(<span class="keyword">this</span>, callfuncN_selector(BlockBoard::call_onBeginAction)),</span><br><span class="line"><span class="literal">nullptr</span>);</span><br><span class="line"><span class="comment">//改成：</span></span><br><span class="line">ac_go = Sequence::create(ac_p,ac_s,ac_s1,CallFuncN::create(CC_CALLBACK_1(BlockBoard::call_onBeginAction,<span class="keyword">this</span>)),</span><br><span class="line"><span class="literal">nullptr</span>);</span><br></pre></td></tr></table></figure><p>CC_CALLBACK_1 CC_CALLBACK_2 CC_CALLBACK_3<br>后面的数字表示带参数的多少。</p><h3 id="ssize-t格式化参数-zd"><a href="#ssize-t格式化参数-zd" class="headerlink" title="ssize_t格式化参数%zd"></a>ssize_t格式化参数%zd</h3><p>ssize_t：有符号整数，与平台无关。适配不同平台的通用整数关键字，在32位平台为32，64位平台为long。<br>size_t：无符号整数，与平台无关。<br>ssize_t格式化参数是%zd, size_t是%tu。</p><h3 id="GameCenter-ReportScore有更新"><a href="#GameCenter-ReportScore有更新" class="headerlink" title="GameCenter ReportScore有更新"></a>GameCenter ReportScore有更新</h3><p>代码如下：<br><figure class="highlight objc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">- (<span class="keyword">void</span>) reportScore: (int64_t) score forCategory: (<span class="built_in">NSString</span>*) category</span><br><span class="line">&#123;</span><br><span class="line">    GKScore *scoreReporter = [[[GKScore alloc] initWithLeaderboardIdentifier:category] autorelease];</span><br><span class="line">    scoreReporter.value = score;</span><br><span class="line">    scoreReporter.context = <span class="number">0</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">NSArray</span> *scores = @[scoreReporter];</span><br><span class="line">    [GKScore reportScores:scores withCompletionHandler:^(<span class="built_in">NSError</span> *error) &#123;</span><br><span class="line">        <span class="comment">//Do something interesting here.</span></span><br><span class="line">        <span class="keyword">if</span> (error != <span class="literal">nil</span>)&#123;</span><br><span class="line">            <span class="comment">// handle the reporting error</span></span><br><span class="line">            <span class="built_in">NSLog</span>(<span class="string">@"上传分数出错."</span>);</span><br><span class="line"></span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="built_in">NSLog</span>(<span class="string">@"上传分数成功"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="Size会有重名错误，用cocos2d-Size"><a href="#Size会有重名错误，用cocos2d-Size" class="headerlink" title="Size会有重名错误，用cocos2d::Size"></a>Size会有重名错误，用cocos2d::Size</h3><h3 id="MenuItemImage-有变化"><a href="#MenuItemImage-有变化" class="headerlink" title="MenuItemImage 有变化"></a>MenuItemImage 有变化</h3><p>代码<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MenuItemImage* item_close = MenuItemImage::create(<span class="string">"close.png"</span>, <span class="string">"close_p.png"</span>,  CC_CALLBACK_1(InfoShowLayer::onClose, <span class="keyword">this</span>));</span><br></pre></td></tr></table></figure></p><h3 id="向量操作"><a href="#向量操作" class="headerlink" title="向量操作"></a>向量操作</h3><p>Vec2可以直接数学符号操作</p><h3 id="Label-Font"><a href="#Label-Font" class="headerlink" title="Label Font"></a>Label Font</h3><p>TTF, 系统字体，BMFont，都由Label类负责创建<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Label* label = Label::createWithSystemFont(str-&gt;getCString(), <span class="string">"Mark Felt"</span>, fontSize);</span><br><span class="line">Label::createWithTTF</span><br><span class="line">Label::createWithBMFont</span><br><span class="line">Label::createWithCharMap</span><br></pre></td></tr></table></figure></p><h3 id="设置资源路径已经适配模式"><a href="#设置资源路径已经适配模式" class="headerlink" title="设置资源路径已经适配模式"></a>设置资源路径已经适配模式</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">searchPath.push_back(<span class="string">"iphone"</span>);</span><br><span class="line">glview&gt;setDesignResolutionSize(<span class="number">750</span>,<span class="number">1334</span>,ResolutionPolicy::FIXED_HEIGHT);</span><br></pre></td></tr></table></figure><h3 id="启动图片和应用图标都有更新"><a href="#启动图片和应用图标都有更新" class="headerlink" title="启动图片和应用图标都有更新"></a>启动图片和应用图标都有更新</h3><p>启动图片决定了初始分辨率的大小。不提供相应的启动图片，不能获得正确的初始分辨率。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.veryitman.com/2018/02/22/NSLog-格式化输出-NSInteger-NSUInteger/" target="_blank" rel="noopener">常用格式化参数</a><br><a href="https://elloop.github.io/cocos2d-x/2016-01-01/cocos2dx-3.x-4-cc-callback-0" target="_blank" rel="noopener">CC_CALLBACK_0, CC_CALLBACK_1, CC_CALLBACK_2, CC_CALLBACK_3</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;更新步骤&quot;&gt;&lt;a href=&quot;#更新步骤&quot; class=&quot;headerlink&quot; title=&quot;更新步骤&quot;&gt;&lt;/a&gt;更新步骤&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;下载开发包（github也可以)。&lt;/li&gt;
&lt;li&gt;运行build目录下，cocos2d_tests.xcod
      
    
    </summary>
    
    
      <category term="cocos2d-x" scheme="https://109383670.github.io/tags/cocos2d-x/"/>
    
      <category term="游戏开发" scheme="https://109383670.github.io/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>Scrapy爬虫项目纪录</title>
    <link href="https://109383670.github.io/2019/02/20/Scrapy%E7%88%AC%E8%99%AB%E9%A1%B9%E7%9B%AE%E7%BA%AA%E5%BD%95/"/>
    <id>https://109383670.github.io/2019/02/20/Scrapy爬虫项目纪录/</id>
    <published>2019-02-19T16:46:54.381Z</published>
    <updated>2019-03-03T08:54:03.522Z</updated>
    
    <content type="html"><![CDATA[<h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><p>从零开始学习scrapy，从搭建环境到完成一个图片网站爬取实例。</p><h3 id="编程环境"><a href="#编程环境" class="headerlink" title="编程环境"></a>编程环境</h3><ul><li>VSCode</li><li>Python3</li><li>Scrapy</li></ul><h3 id="安装记录"><a href="#安装记录" class="headerlink" title="安装记录"></a>安装记录</h3><h4 id="win下安装"><a href="#win下安装" class="headerlink" title="win下安装"></a>win下安装</h4><h5 id="用pip命令安装Scrapy时提示没有MS框架"><a href="#用pip命令安装Scrapy时提示没有MS框架" class="headerlink" title="用pip命令安装Scrapy时提示没有MS框架"></a>用pip命令安装Scrapy时提示没有MS框架</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">安装MS Build TOOL</span><br></pre></td></tr></table></figure><h5 id="提示没有安装win32api"><a href="#提示没有安装win32api" class="headerlink" title="提示没有安装win32api"></a>提示没有安装win32api</h5><p>用pip 安装win32：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pywin32</span><br></pre></td></tr></table></figure><h5 id="安装命令"><a href="#安装命令" class="headerlink" title="安装命令"></a>安装命令</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install scrapy</span><br></pre></td></tr></table></figure><p>更新命令<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install --upgrade scrapy</span><br></pre></td></tr></table></figure></p><h4 id="mac-下安装"><a href="#mac-下安装" class="headerlink" title="mac 下安装"></a>mac 下安装</h4><p>mac 自带的python是2.7版本的，而且不能升级，否则会影响系统的功能。<br>mac下用Homebrew来进行升级</p><ol><li><p>安装xcode命令行工具</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xcode-select --install</span><br></pre></td></tr></table></figure></li><li><p><a href="https://brew.sh/" target="_blank" rel="noopener">https://brew.sh/</a> 安装Homebrew</p></li><li><p>将Homebrew加入环境变量中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"export PATH=/usr/local/bin:/usr/local/sbin:<span class="variable">$PATH</span>"</span> &gt;&gt; ~/.bashrc</span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure></li><li><p>安装python</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install python</span><br></pre></td></tr></table></figure><p> 如果已经安装，可以进行升级</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew update; brew upgrade python</span><br></pre></td></tr></table></figure><ol start="5"><li>安装scrapy<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install scrapy</span><br></pre></td></tr></table></figure></li></ol></li></ol><h3 id="学习记录"><a href="#学习记录" class="headerlink" title="学习记录"></a>学习记录</h3><h4 id="生成Scrapy框架"><a href="#生成Scrapy框架" class="headerlink" title="生成Scrapy框架"></a>生成Scrapy框架</h4><p>SCrapy必须在固定的框架下运行，可以自动生成后再去改动。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject 工程名</span><br></pre></td></tr></table></figure></p><h4 id="HelloWorld代码"><a href="#HelloWorld代码" class="headerlink" title="HelloWorld代码"></a>HelloWorld代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span>  <span class="comment"># 任何爬虫都要继承Scrapy.Spider这个类，复写它的方法</span></span><br><span class="line"></span><br><span class="line">    name = <span class="string">"quotes"</span>    <span class="comment"># 唯一的爬虫名字，在运行时要用到</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span>    <span class="comment"># 复写的方法，初始请求的网址</span></span><br><span class="line">        urls = [</span><br><span class="line">            <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">            <span class="string">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class="line">        ]</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span>       <span class="comment"># 复写的方法，在这里对爬下的数据进行处理</span></span><br><span class="line">        page = response.url.split(<span class="string">"/"</span>)[<span class="number">-2</span>]</span><br><span class="line">        filename = <span class="string">'quotes-%s.html'</span> % page</span><br><span class="line">        <span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br><span class="line">        self.log(<span class="string">'Saved file %s'</span> % filename)</span><br></pre></td></tr></table></figure><p>运行命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl quotes</span><br></pre></td></tr></table></figure> <a id="more"></a><h4 id="深入学习"><a href="#深入学习" class="headerlink" title="深入学习"></a>深入学习</h4><h5 id="例子1-提取内容"><a href="#例子1-提取内容" class="headerlink" title="例子1-提取内容"></a>例子1-提取内容</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提取相关格言以及作者等信息</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).get(),</span><br><span class="line">                <span class="string">'author'</span>: quote.css(<span class="string">'small.author::text'</span>).get(),</span><br><span class="line">                <span class="string">'tags'</span>: quote.css(<span class="string">'div.tags a.tag::text'</span>).getall(),</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure><p>输出json或者jl(JSON Lines)命令<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl quotes -o quotes.json</span><br><span class="line"></span><br><span class="line">scrapy crawl quotes -o quotes.jl</span><br></pre></td></tr></table></figure></p><h5 id="例子2-爬取下一个链接"><a href="#例子2-爬取下一个链接" class="headerlink" title="例子2-爬取下一个链接"></a>例子2-爬取下一个链接</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).get(),</span><br><span class="line">                <span class="string">'author'</span>: quote.css(<span class="string">'small.author::text'</span>).get(),</span><br><span class="line">                <span class="string">'tags'</span>: quote.css(<span class="string">'div.tags a.tag::text'</span>).getall(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).get()</span><br><span class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            next_page = response.urljoin(next_page)     <span class="comment">#获得真实的链接地址</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(next_page, callback=self.parse)  <span class="comment">#下一个链接的处理回调</span></span><br></pre></td></tr></table></figure><p>后面两句可以用下面的代替，不用写urljoin了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">yield</span> response.follow(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure><p>进一步简化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'li.next a::attr(href)'</span>):</span><br><span class="line">    <span class="keyword">yield</span> response.follow(href, callback=self.parse)</span><br></pre></td></tr></table></figure><p>再进一步简化：<br>对于a 标签，会自动使用它的href属性<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> response.css(<span class="string">'li.next a'</span>):</span><br><span class="line">    <span class="keyword">yield</span> response.follow(a, callback=self.parse)</span><br></pre></td></tr></table></figure></p><h5 id="进阶例子"><a href="#进阶例子" class="headerlink" title="进阶例子"></a>进阶例子</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AuthorSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'author'</span></span><br><span class="line"></span><br><span class="line">    start_urls = [<span class="string">'http://quotes.toscrape.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment"># follow links to author pages</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'.author + a::attr(href)'</span>):</span><br><span class="line">            <span class="keyword">yield</span> response.follow(href, self.parse_author)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># follow pagination links</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'li.next a::attr(href)'</span>):</span><br><span class="line">            <span class="keyword">yield</span> response.follow(href, self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_author</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">extract_with_css</span><span class="params">(query)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> response.css(query).get(default=<span class="string">''</span>).strip()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">'name'</span>: extract_with_css(<span class="string">'h3.author-title::text'</span>),</span><br><span class="line">            <span class="string">'birthdate'</span>: extract_with_css(<span class="string">'.author-born-date::text'</span>),</span><br><span class="line">            <span class="string">'bio'</span>: extract_with_css(<span class="string">'.author-description::text'</span>),</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><h5 id="命令行参数例子"><a href="#命令行参数例子" class="headerlink" title="命令行参数例子"></a>命令行参数例子</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        url = <span class="string">'http://quotes.toscrape.com/'</span></span><br><span class="line">        tag = getattr(self, <span class="string">'tag'</span>, <span class="literal">None</span>)    <span class="comment">#从命令行参数获得</span></span><br><span class="line">        <span class="keyword">if</span> tag <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            url = url + <span class="string">'tag/'</span> + tag</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url, self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).get(),</span><br><span class="line">                <span class="string">'author'</span>: quote.css(<span class="string">'small.author::text'</span>).get(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).get()</span><br><span class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">yield</span> response.follow(next_page, self.parse)</span><br></pre></td></tr></table></figure><p>命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl quotes -o quotes-humor.json -a tag=humor</span><br></pre></td></tr></table></figure><p>结果</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://quotes.toscrape.com/tag/humor</span><br></pre></td></tr></table></figure><h5 id="item"><a href="#item" class="headerlink" title="item"></a>item</h5><p>可以自己定义的数据结构<br>格式如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Product</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    name = scrapy.Field()</span><br><span class="line">    price = scrapy.Field()</span><br><span class="line">    stock = scrapy.Field()</span><br><span class="line">    last_updated = scrapy.Field(serializer=str)</span><br></pre></td></tr></table></figure></p><h5 id="item-pipeline"><a href="#item-pipeline" class="headerlink" title="item pipeline"></a>item pipeline</h5><p>处理item数据的地方，在parse中返回item,就会调用该方法。<br>格式如下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PricePipeline</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    vat_factor = <span class="number">1.15</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> item.get(<span class="string">'price'</span>):</span><br><span class="line">            <span class="keyword">if</span> item.get(<span class="string">'price_excludes_vat'</span>):</span><br><span class="line">                item[<span class="string">'price'</span>] = item[<span class="string">'price'</span>] * self.vat_factor</span><br><span class="line">            <span class="keyword">return</span> item</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">"Missing price in %s"</span> % item)</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JsonWriterPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        self.file = open(<span class="string">'items.jl'</span>, <span class="string">'w'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        self.file.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        line = json.dumps(dict(item)) + <span class="string">"\n"</span></span><br><span class="line">        self.file.write(line)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure><p>在setting里启动pipeline<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'myproject.pipelines.PricePipeline'</span>: <span class="number">300</span>,   <span class="comment">#数字表示优先顺序，越小的越先执行</span></span><br><span class="line">    <span class="string">'myproject.pipelines.JsonWriterPipeline'</span>: <span class="number">800</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mySpider.items <span class="keyword">import</span> ItcastItem</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    <span class="comment">#open("teacher.html","wb").write(response.body).close()</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 存放老师信息的集合</span></span><br><span class="line">    <span class="comment">#items = []</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> response.xpath(<span class="string">"//div[@class='li_txt']"</span>):</span><br><span class="line">        <span class="comment"># 将我们得到的数据封装到一个 `ItcastItem` 对象</span></span><br><span class="line">        item = ItcastItem()</span><br><span class="line">        <span class="comment">#extract()方法返回的都是unicode字符串</span></span><br><span class="line">        name = each.xpath(<span class="string">"h3/text()"</span>).extract()</span><br><span class="line">        title = each.xpath(<span class="string">"h4/text()"</span>).extract()</span><br><span class="line">        info = each.xpath(<span class="string">"p/text()"</span>).extract()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#xpath返回的是包含一个元素的列表</span></span><br><span class="line">        item[<span class="string">'name'</span>] = name[<span class="number">0</span>]</span><br><span class="line">        item[<span class="string">'title'</span>] = title[<span class="number">0</span>]</span><br><span class="line">        item[<span class="string">'info'</span>] = info[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment">#items.append(item)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#将获取的数据交给pipelines</span></span><br><span class="line">        <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回数据，不经过pipeline</span></span><br><span class="line">    <span class="comment">#return items</span></span><br></pre></td></tr></table></figure></p><h5 id="中文乱码转为utf-8"><a href="#中文乱码转为utf-8" class="headerlink" title="中文乱码转为utf-8"></a>中文乱码转为utf-8</h5><p>python3默认为unicode,如果输出为中文，则要转为utf-8，不然会是乱码<br>代码如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Pipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.file = codecs.open(</span><br><span class="line">            <span class="string">'items.json'</span>, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        self.file.seek(<span class="number">-1</span>, os.SEEK_END)</span><br><span class="line">        self.file.truncate()</span><br><span class="line">        self.file.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        line = json.dumps(dict(item), ensure_ascii=<span class="literal">False</span>) + <span class="string">"\n"</span></span><br><span class="line">        self.file.write(line)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure></p><h5 id="imagepipeline各函数运行流程"><a href="#imagepipeline各函数运行流程" class="headerlink" title="imagepipeline各函数运行流程"></a>imagepipeline各函数运行流程</h5><ol><li>imagepipeline启动</li><li>get_media_requests 将所有的下载请求一次全部完成</li><li>下载完成后再统一执行item_completed</li></ol><h5 id="同时下载多个图片并改名"><a href="#同时下载多个图片并改名" class="headerlink" title="同时下载多个图片并改名"></a>同时下载多个图片并改名</h5><p>重写file_path函数实现<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(self, item, info)</span>:</span></span><br><span class="line">      <span class="string">"""</span></span><br><span class="line"><span class="string">      :param item: spider.py中返回的item</span></span><br><span class="line"><span class="string">      :param info:</span></span><br><span class="line"><span class="string">      :return:</span></span><br><span class="line"><span class="string">      """</span></span><br><span class="line">      <span class="comment">#这里传递字符，或者图片列表，如果是单个的对象，则非常容易被覆盖</span></span><br><span class="line">      <span class="keyword">yield</span> scrapy.Request(item[<span class="string">'pic_url'</span>], meta=&#123;<span class="string">'item'</span>: item[<span class="string">'pic_name'</span>]&#125;)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">file_path</span><span class="params">(self, request, response=None, info=None)</span>:</span></span><br><span class="line">      <span class="string">"""</span></span><br><span class="line"><span class="string">      : param request: 每一个图片下载管道请求</span></span><br><span class="line"><span class="string">      : param response:</span></span><br><span class="line"><span class="string">      : param info:</span></span><br><span class="line"><span class="string">      : param strip: 清洗Windows系统的文件夹非法字符，避免无法创建目录</span></span><br><span class="line"><span class="string">      : return: 每套图的分类目录</span></span><br><span class="line"><span class="string">      """</span></span><br><span class="line">      item = request.meta[<span class="string">'item'</span>]</span><br><span class="line">      folder = item</span><br><span class="line">      folder_strip = strip(folder)</span><br><span class="line">      <span class="comment"># img_path = "%s%s" % (self.img_store, folder_strip)</span></span><br><span class="line">      filename = folder_strip + <span class="string">'/'</span> + folder_strip + <span class="string">'.jpg'</span></span><br><span class="line">      <span class="keyword">return</span> filename</span><br><span class="line">      </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">strip</span><span class="params">(path)</span>:</span></span><br><span class="line">  <span class="string">"""</span></span><br><span class="line"><span class="string">  :param path: 需要清洗的文件夹名字</span></span><br><span class="line"><span class="string">  :return: 清洗掉Windows系统非法文件夹名字的字符串</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  path = re.sub(<span class="string">r'[？\\*|“&lt;&gt;:/]'</span>, <span class="string">''</span>, str(path))</span><br><span class="line">  <span class="keyword">return</span> path</span><br></pre></td></tr></table></figure></p><h5 id="Request-回调传递参数"><a href="#Request-回调传递参数" class="headerlink" title="Request 回调传递参数"></a>Request 回调传递参数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scrapy.Request(next_page, callback=self.parse_imgs, meta=&#123;<span class="string">'item'</span>: item, <span class="string">'param'</span>: name&#125;)</span><br><span class="line"></span><br><span class="line">在parse中提取参数</span><br><span class="line">item = response.meta[<span class="string">'item'</span>]</span><br></pre></td></tr></table></figure><h5 id="结果去重"><a href="#结果去重" class="headerlink" title="结果去重"></a>结果去重</h5><ol><li>Request的参数 dont_filter=False 默认去重</li><li>启用一个爬虫的持久化，运行以下命令:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl somespider -s JOBDIR=crawls/somespider-1</span><br></pre></td></tr></table></figure></li></ol><p>然后，你就能在任何时候安全地停止爬虫(按Ctrl-C或者发送一个信号)。<br>恢复这个爬虫也是同样的命令:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl somespider -s JOBDIR=crawls/somespider-1</span><br></pre></td></tr></table></figure></p><p>这样爬虫断掉后，再启动会接着上次的 url 跑。</p><p>如果命令行里不想看到那么多输出的话，可以加个 -L WARNING 参数<br>运行爬虫如：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl spider1 -L WARNING</span><br></pre></td></tr></table></figure></p><p>不打印Debug信息，可以清楚得看到运行过程。</p><ol><li>scrapy-red</li></ol><h3 id="错误记录"><a href="#错误记录" class="headerlink" title="错误记录"></a>错误记录</h3><h4 id="pipeline-is-not-a-full-path"><a href="#pipeline-is-not-a-full-path" class="headerlink" title="pipeline is not a full path"></a>pipeline is not a full path</h4><p>应该在 setting 中填入完整的管道的路径，如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pic.pipelines.PicImagesDownloadPipeline</span><br></pre></td></tr></table></figure></p><p>如果只填PicImagesDownloadPipeline,就会出现这个错误。</p><h4 id="Symbol-not-found-PyInt-AsLong-错误"><a href="#Symbol-not-found-PyInt-AsLong-错误" class="headerlink" title="Symbol not found:  _PyInt_AsLong 错误"></a>Symbol not found:  _PyInt_AsLong 错误</h4><p>将系统python目录下的PIL和Pillow库都删除，再用pip3安装在 Python3的安装目录下<br>系统python安装目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/Library/Python/2.7/site-packages</span><br></pre></td></tr></table></figure></p><h4 id="Missing-scheme-in-request-url-h"><a href="#Missing-scheme-in-request-url-h" class="headerlink" title="Missing scheme in request url: h"></a>Missing scheme in request url: h</h4><p>相关URL必须是一个List，所以遇到该错误只需要将url转换成list即可。<br>例如：<br>start_urls = [‘someurls’]<br>如果是images_url也是如此，使用item存储的时候改成list即可。<br>item[‘images_urls’] = [‘image_url’]</p><h4 id="Request-url-must-be-str-or-unicode"><a href="#Request-url-must-be-str-or-unicode" class="headerlink" title="Request url must be str or unicode"></a>Request url must be str or unicode</h4><p>请求的url参数不能是一个列表，必须是一个字符</p><h4 id="在item-complete中改名多个图片不成功"><a href="#在item-complete中改名多个图片不成功" class="headerlink" title="在item_complete中改名多个图片不成功"></a>在item_complete中改名多个图片不成功</h4><p>item_complete并不是在get_media_requests下载图片后马上启动的，它是要等所有的图片下载完成，再统一启动complete事件，这样就导致多个图片没法改名，不能获得之前的item的字段。改名需要重写file_path</p><h4 id="get-media-requests中回调参数要小心"><a href="#get-media-requests中回调参数要小心" class="headerlink" title="get_media_requests中回调参数要小心"></a>get_media_requests中回调参数要小心</h4><p>meta中可以加入回调的参数，如果传递的是对象要非常小心，如果对象发生变化，会导致后面所有的回调参数发生变化，传递的如果是字符，就没有这个风险。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(self, item, info)</span>:</span></span><br><span class="line">       <span class="string">"""</span></span><br><span class="line"><span class="string">       :param item: spider.py中返回的item</span></span><br><span class="line"><span class="string">       :param info:</span></span><br><span class="line"><span class="string">       :return:</span></span><br><span class="line"><span class="string">       """</span></span><br><span class="line">       <span class="keyword">yield</span> scrapy.Request(item[<span class="string">'pic_url'</span>], meta=&#123;<span class="string">'item'</span>: item[<span class="string">'pic_name'</span>]&#125;)</span><br></pre></td></tr></table></figure></p><h4 id="Filtered-duplicate-request"><a href="#Filtered-duplicate-request" class="headerlink" title="Filtered duplicate request"></a>Filtered duplicate request</h4><p>有重复下载的请求，如果要重复下载，在<em>Request函数</em>里加上参数 <em>dont_filter=True</em>，默认是<em>False</em></p><h3 id="最终代码"><a href="#最终代码" class="headerlink" title="最终代码"></a>最终代码</h3><p>piczz.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> piczz.items <span class="keyword">import</span> PiczzItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">piczzSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"piczz"</span></span><br><span class="line">    allowed_domains = [<span class="string">""</span>]</span><br><span class="line">    start_urls = [<span class="string">""</span>]</span><br><span class="line">    img_paths = []</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> response.xpath(</span><br><span class="line">                <span class="string">"//div[@class = 'post_box']"</span>):</span><br><span class="line">            <span class="comment"># extract()方法返回的都是unicode字符串</span></span><br><span class="line">            item = PiczzItem()</span><br><span class="line">            item[<span class="string">'name'</span>] = <span class="string">'startpage'</span></span><br><span class="line"></span><br><span class="line">            self.img_paths.clear()</span><br><span class="line">            item[<span class="string">'pic_name'</span>] = each.xpath(</span><br><span class="line">                <span class="string">"descendant::div[@class = 'tit']/h2[@class = 'h1']/a/text()"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            item[<span class="string">'pic_url'</span>] = each.xpath(</span><br><span class="line">                <span class="string">"descendant::div[@class = 'tit']/h2[@class = 'h1']/a/@href"</span>).extract()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(item[<span class="string">'pic_url'</span>],</span><br><span class="line">                                 callback=self.parse_imgs, meta=&#123;<span class="string">'item'</span>: item&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#递归下一页图片</span></span><br><span class="line">        next_path = response.xpath(</span><br><span class="line">            <span class="string">"descendant::div[@class = 'page_num']/a[last()]"</span>)</span><br><span class="line">        next_con = next_path.xpath(<span class="string">"text()"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        next_con = next_con.strip()</span><br><span class="line">        next_page = <span class="string">""</span></span><br><span class="line">        <span class="keyword">if</span> next_con == <span class="string">"下一頁 »"</span>:</span><br><span class="line">            next_page = next_path.xpath(<span class="string">"@href"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            print(next_page)</span><br><span class="line">            <span class="keyword">if</span> next_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">yield</span> scrapy.Request(next_page, self.parse)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 下载一个索引页的图片</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_imgs</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        self.img_paths.clear()</span><br><span class="line">        item = response.meta[<span class="string">'item'</span>]</span><br><span class="line">        imgs = response.xpath(</span><br><span class="line">            <span class="string">"descendant::div[@class = 'entry-content']/p/img/@src"</span>).extract()</span><br><span class="line">        <span class="keyword">for</span> e <span class="keyword">in</span> imgs:</span><br><span class="line">            self.img_paths.append(e)</span><br><span class="line">        item[<span class="string">'pic_paths'</span>] = self.img_paths</span><br><span class="line">        next_path = response.xpath(</span><br><span class="line">            <span class="string">"descendant::div[@class = 'wp-pagenavi']/p/a[last()]"</span>)</span><br><span class="line">        next_con = next_path.xpath(<span class="string">"text()"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">        next_con = next_con.strip()</span><br><span class="line">        <span class="keyword">if</span> next_con == <span class="string">"下一页"</span>:</span><br><span class="line">            next_page = next_path.xpath(<span class="string">"@href"</span>).extract()[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">yield</span> scrapy.Request(next_page, callback=self.parse_imgs, meta=&#123;<span class="string">'item'</span>: item&#125;)</span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure></p><p>item.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PiczzItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    name = scrapy.Field()</span><br><span class="line">    pic_name = scrapy.Field()  <span class="comment"># 图片目录名</span></span><br><span class="line">    pic_url = scrapy.Field()  <span class="comment"># 图片索引首页地址</span></span><br><span class="line">    pic_paths = scrapy.Field()  <span class="comment"># 图片下载地址列表</span></span><br></pre></td></tr></table></figure><p>pipeline.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> PIL</span><br><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.project <span class="keyword">import</span> get_project_settings</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PiczzImagesDownloadPipeline</span><span class="params">(ImagesPipeline)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(self, item, info)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param item: spider.py中返回的item</span></span><br><span class="line"><span class="string">        :param info:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">for</span> img_url <span class="keyword">in</span> item[<span class="string">'pic_paths'</span>]:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(img_url, meta=&#123;<span class="string">'item'</span>: item[<span class="string">'pic_name'</span>]&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">file_path</span><span class="params">(self, request, response=None, info=None)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        : param request: 每一个图片下载管道请求</span></span><br><span class="line"><span class="string">        : param response:</span></span><br><span class="line"><span class="string">        : param info:</span></span><br><span class="line"><span class="string">        : param strip: 清洗Windows系统的文件夹非法字符，避免无法创建目录</span></span><br><span class="line"><span class="string">        : return: 每套图的分类目录</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        item = request.meta[<span class="string">'item'</span>]</span><br><span class="line">        folder = item</span><br><span class="line">        folder_strip = strip(folder)</span><br><span class="line">        image_guid = request.url.split(<span class="string">'/'</span>)[<span class="number">-1</span>]</span><br><span class="line">        filename = folder_strip + <span class="string">'/'</span> + image_guid + <span class="string">'.jpg'</span></span><br><span class="line">        <span class="keyword">return</span> filename</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span><span class="params">(self, results, item, info)</span>:</span></span><br><span class="line">        image_paths = [x[<span class="string">'path'</span>] <span class="keyword">for</span> ok, x <span class="keyword">in</span> results <span class="keyword">if</span> ok]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> image_paths:</span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">"Item contains no images"</span>)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">strip</span><span class="params">(path)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    :param path: 需要清洗的文件夹名字</span></span><br><span class="line"><span class="string">    :return: 清洗掉Windows系统非法文件夹名字的字符串</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    path = re.sub(<span class="string">r'[？\\*|“&lt;&gt;:/]'</span>, <span class="string">''</span>, str(path))</span><br><span class="line">    <span class="keyword">return</span> path</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>从搭建环境到断断续续的学习花了大概五天时间 ，每天平均花二个小时学习，终于成功的将设定的目标完成。</p><h3 id="参考网站"><a href="#参考网站" class="headerlink" title="参考网站"></a>参考网站</h3><p><a href="https://docs.scrapy.org/en/latest/" target="_blank" rel="noopener">官网</a><br><a href="https://scrapy-chs.readthedocs.io/zh_CN/latest/intro/install.html" target="_blank" rel="noopener">中文参考网站</a><br><a href="http://www.w3school.com.cn/xpath/xpath_syntax.asp" target="_blank" rel="noopener">xPath语法</a><br><a href="http://python.jobbole.com/83610/" target="_blank" rel="noopener">Python中yield的解释</a><br><a href="https://blog.csdn.net/a542551042/article/details/47149959" target="_blank" rel="noopener">mac os Python路径总结</a><br><a href="https://segmentfault.com/a/1190000013178839" target="_blank" rel="noopener">Scrapy框架入门简介</a><br><a href="https://segmentfault.com/a/1190000009597329" target="_blank" rel="noopener">ImagesPipeline下载图片</a><br><a href="https://segmentfault.com/q/1010000000413334" target="_blank" rel="noopener">ImagesPipeline下载图片保持原文件名</a><br><a href="https://cuiqingcai.com/4421.html" target="_blank" rel="noopener">小白进阶之Scrapy第四篇</a><br><a href="http://python.jobbole.com/83610/" target="_blank" rel="noopener">Python中yield的解释</a><br><a href="https://blog.csdn.net/heheyanyanjun/article/details/79199378" target="_blank" rel="noopener">scrapy调用parse()中使用yield引发对yield的分析</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;目标&quot;&gt;&lt;a href=&quot;#目标&quot; class=&quot;headerlink&quot; title=&quot;目标&quot;&gt;&lt;/a&gt;目标&lt;/h3&gt;&lt;p&gt;从零开始学习scrapy，从搭建环境到完成一个图片网站爬取实例。&lt;/p&gt;
&lt;h3 id=&quot;编程环境&quot;&gt;&lt;a href=&quot;#编程环境&quot; class=&quot;headerlink&quot; title=&quot;编程环境&quot;&gt;&lt;/a&gt;编程环境&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;VSCode&lt;/li&gt;
&lt;li&gt;Python3&lt;/li&gt;
&lt;li&gt;Scrapy&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;安装记录&quot;&gt;&lt;a href=&quot;#安装记录&quot; class=&quot;headerlink&quot; title=&quot;安装记录&quot;&gt;&lt;/a&gt;安装记录&lt;/h3&gt;&lt;h4 id=&quot;win下安装&quot;&gt;&lt;a href=&quot;#win下安装&quot; class=&quot;headerlink&quot; title=&quot;win下安装&quot;&gt;&lt;/a&gt;win下安装&lt;/h4&gt;&lt;h5 id=&quot;用pip命令安装Scrapy时提示没有MS框架&quot;&gt;&lt;a href=&quot;#用pip命令安装Scrapy时提示没有MS框架&quot; class=&quot;headerlink&quot; title=&quot;用pip命令安装Scrapy时提示没有MS框架&quot;&gt;&lt;/a&gt;用pip命令安装Scrapy时提示没有MS框架&lt;/h5&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;安装MS Build TOOL&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h5 id=&quot;提示没有安装win32api&quot;&gt;&lt;a href=&quot;#提示没有安装win32api&quot; class=&quot;headerlink&quot; title=&quot;提示没有安装win32api&quot;&gt;&lt;/a&gt;提示没有安装win32api&lt;/h5&gt;&lt;p&gt;用pip 安装win32：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;pip install pywin32&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h5 id=&quot;安装命令&quot;&gt;&lt;a href=&quot;#安装命令&quot; class=&quot;headerlink&quot; title=&quot;安装命令&quot;&gt;&lt;/a&gt;安装命令&lt;/h5&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;pip install scrapy&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;更新命令&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo pip install --upgrade scrapy&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&quot;mac-下安装&quot;&gt;&lt;a href=&quot;#mac-下安装&quot; class=&quot;headerlink&quot; title=&quot;mac 下安装&quot;&gt;&lt;/a&gt;mac 下安装&lt;/h4&gt;&lt;p&gt;mac 自带的python是2.7版本的，而且不能升级，否则会影响系统的功能。&lt;br&gt;mac下用Homebrew来进行升级&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;安装xcode命令行工具&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;xcode-select --install&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&quot;https://brew.sh/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://brew.sh/&lt;/a&gt; 安装Homebrew&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;将Homebrew加入环境变量中&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;export PATH=/usr/local/bin:/usr/local/sbin:&lt;span class=&quot;variable&quot;&gt;$PATH&lt;/span&gt;&quot;&lt;/span&gt; &amp;gt;&amp;gt; ~/.bashrc&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;source&lt;/span&gt; ~/.bashrc&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;安装python&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;brew install python&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt; 如果已经安装，可以进行升级&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;brew update; brew upgrade python&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;ol start=&quot;5&quot;&gt;
&lt;li&gt;安装scrapy&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;pip3 install scrapy&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;学习记录&quot;&gt;&lt;a href=&quot;#学习记录&quot; class=&quot;headerlink&quot; title=&quot;学习记录&quot;&gt;&lt;/a&gt;学习记录&lt;/h3&gt;&lt;h4 id=&quot;生成Scrapy框架&quot;&gt;&lt;a href=&quot;#生成Scrapy框架&quot; class=&quot;headerlink&quot; title=&quot;生成Scrapy框架&quot;&gt;&lt;/a&gt;生成Scrapy框架&lt;/h4&gt;&lt;p&gt;SCrapy必须在固定的框架下运行，可以自动生成后再去改动。&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;scrapy startproject 工程名&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&quot;HelloWorld代码&quot;&gt;&lt;a href=&quot;#HelloWorld代码&quot; class=&quot;headerlink&quot; title=&quot;HelloWorld代码&quot;&gt;&lt;/a&gt;HelloWorld代码&lt;/h4&gt;&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; scrapy&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;QuotesSpider&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(scrapy.Spider)&lt;/span&gt;:&lt;/span&gt;  &lt;span class=&quot;comment&quot;&gt;# 任何爬虫都要继承Scrapy.Spider这个类，复写它的方法&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    name = &lt;span class=&quot;string&quot;&gt;&quot;quotes&quot;&lt;/span&gt;    &lt;span class=&quot;comment&quot;&gt;# 唯一的爬虫名字，在运行时要用到&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;start_requests&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self)&lt;/span&gt;:&lt;/span&gt;    &lt;span class=&quot;comment&quot;&gt;# 复写的方法，初始请求的网址&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        urls = [&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;string&quot;&gt;&#39;http://quotes.toscrape.com/page/1/&#39;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;string&quot;&gt;&#39;http://quotes.toscrape.com/page/2/&#39;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        ]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; url &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; urls:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;keyword&quot;&gt;yield&lt;/span&gt; scrapy.Request(url=url, callback=self.parse)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, response)&lt;/span&gt;:&lt;/span&gt;       &lt;span class=&quot;comment&quot;&gt;# 复写的方法，在这里对爬下的数据进行处理&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        page = response.url.split(&lt;span class=&quot;string&quot;&gt;&quot;/&quot;&lt;/span&gt;)[&lt;span class=&quot;number&quot;&gt;-2&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        filename = &lt;span class=&quot;string&quot;&gt;&#39;quotes-%s.html&#39;&lt;/span&gt; % page&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;with&lt;/span&gt; open(filename, &lt;span class=&quot;string&quot;&gt;&#39;wb&#39;&lt;/span&gt;) &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; f:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            f.write(response.body)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        self.log(&lt;span class=&quot;string&quot;&gt;&#39;Saved file %s&#39;&lt;/span&gt; % filename)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;运行命令：&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;scrapy crawl quotes&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Scrapy" scheme="https://109383670.github.io/tags/Scrapy/"/>
    
      <category term="Python" scheme="https://109383670.github.io/tags/Python/"/>
    
      <category term="爬虫" scheme="https://109383670.github.io/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>egret与cocos creator</title>
    <link href="https://109383670.github.io/2017/03/11/egret%E4%B8%8Ecocos%20creator/"/>
    <id>https://109383670.github.io/2017/03/11/egret与cocos creator/</id>
    <published>2017-03-11T08:18:43.000Z</published>
    <updated>2017-03-11T09:04:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>花了点时间分别体验了两个html5游戏制作工具：egret与cocos2d creator。<br>为了更好的对比，同时用两个工具做一个简单的射击demo。<br>使用后的体会：</p><h2 id="egret-（白鹭）"><a href="#egret-（白鹭）" class="headerlink" title="egret （白鹭）"></a>egret （白鹭）</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol><li>开发工具齐全，从龙骨、粒子系统、资源管理、编译器等，基本上你需要的都提供了，省去了四处去找第三方工具库的麻烦，这个非常好。  </li><li>开发用的是TypeScript语言。在没有任何基础的情况下，我边看例子，边学习TypeScript, 没有什么大的障碍。调试功能也整合得很好。  </li><li>用exml进行UI可视化，直观，上手容易。</li><li>提供云测试空间，可以直接发布免费提供的ft空间进行测试。想到真是太周到了，这是一条龙服务的节奏。</li></ol><h3 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h3><ol><li>教程文档混乱，调试一个问题花了几个小时没找到原因，结果发现是一个类文件没有放在src的文件夹下，这么重要的东西，竟然在文档中没任何提及。</li><li>exml这样的ui方式，对于初学者来说太过复杂了，刚开始学习的人，估计一头雾水，加上文档有混乱，入坑门槛比较高。</li><li>在物理系统，碰撞系统的支持上，比较弱，可能html5游戏应该也用不到这么复杂的功能。</li></ol><h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p>如果要开发html5游戏，之前用过cocos2d-x之类的，没有用过unity开发的，可以用egret。如果要进行大规模商业开发的，也建议用这个，各个功能比较完善，是成熟的产品。</p><a id="more"></a><h2 id="coco2d-creator"><a href="#coco2d-creator" class="headerlink" title="coco2d creator"></a>coco2d creator</h2><h3 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h3><ol><li>文档、教程详细，写的非常好，基本上你想知道的全部有。从零开始到完成helloworld, 一套龙。教程友好，文档规范合理，用起来太舒服了。</li><li>用javascript进行开发，基于数据驱动的组件思想，入手快，开发直观。</li><li>对碰撞、地图的支持很好。</li></ol><h3 id="缺点：-1"><a href="#缺点：-1" class="headerlink" title="缺点："></a>缺点：</h3><ol><li>vscode的代码提示基本没用，得一个一个查文档。</li><li>调试功能差，估计调试错误花费的时间比较高。</li><li>有些功能还不完善。</li></ol><h3 id="总结：-1"><a href="#总结：-1" class="headerlink" title="总结："></a>总结：</h3><p>如果是之前用过unity开发的，那就太舒服了，基本上可以一边看文档一边做，没什么难度，上手快，用来做小游戏应该很爽。</p><h2 id="对比总结："><a href="#对比总结：" class="headerlink" title="对比总结："></a>对比总结：</h2><p>cocos2d creator就是模仿unity，打造一个轻型的html5制作工具。不得不说击中了unity在html5开发上的弱点。很看好cocos2d creator，相信在王哲的带领下，功能会越来越多，工具也会越来越完善。<br>cocos2d creator虽然以cocos2d-x为底层，但是有意思的是，egret才是以代码为驱动，用代码控制一切，cocos2d creator以数据为驱动，用组件的方式，跟unity一致。<br>egret像cocos2d-x, cocos2d creator像unity。<br>两个工具各有千秋，一个是以代码驱动，一个以数据驱动。选择一种就是选择一种不同设计方法。</p><h2 id="Demo地址"><a href="#Demo地址" class="headerlink" title="Demo地址"></a>Demo地址</h2><p><a href="https://github.com/109383670/ShootSomething" target="_blank" rel="noopener">Github代码</a><br><a href="http://wingftp.open.egret.com/ftproot/109383670/" target="_blank" rel="noopener">点击预览游戏</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;花了点时间分别体验了两个html5游戏制作工具：egret与cocos2d creator。&lt;br&gt;为了更好的对比，同时用两个工具做一个简单的射击demo。&lt;br&gt;使用后的体会：&lt;/p&gt;
&lt;h2 id=&quot;egret-（白鹭）&quot;&gt;&lt;a href=&quot;#egret-（白鹭）&quot; class=&quot;headerlink&quot; title=&quot;egret （白鹭）&quot;&gt;&lt;/a&gt;egret （白鹭）&lt;/h2&gt;&lt;h3 id=&quot;优点&quot;&gt;&lt;a href=&quot;#优点&quot; class=&quot;headerlink&quot; title=&quot;优点&quot;&gt;&lt;/a&gt;优点&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;开发工具齐全，从龙骨、粒子系统、资源管理、编译器等，基本上你需要的都提供了，省去了四处去找第三方工具库的麻烦，这个非常好。  &lt;/li&gt;
&lt;li&gt;开发用的是TypeScript语言。在没有任何基础的情况下，我边看例子，边学习TypeScript, 没有什么大的障碍。调试功能也整合得很好。  &lt;/li&gt;
&lt;li&gt;用exml进行UI可视化，直观，上手容易。&lt;/li&gt;
&lt;li&gt;提供云测试空间，可以直接发布免费提供的ft空间进行测试。想到真是太周到了，这是一条龙服务的节奏。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;缺点：&quot;&gt;&lt;a href=&quot;#缺点：&quot; class=&quot;headerlink&quot; title=&quot;缺点：&quot;&gt;&lt;/a&gt;缺点：&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;教程文档混乱，调试一个问题花了几个小时没找到原因，结果发现是一个类文件没有放在src的文件夹下，这么重要的东西，竟然在文档中没任何提及。&lt;/li&gt;
&lt;li&gt;exml这样的ui方式，对于初学者来说太过复杂了，刚开始学习的人，估计一头雾水，加上文档有混乱，入坑门槛比较高。&lt;/li&gt;
&lt;li&gt;在物理系统，碰撞系统的支持上，比较弱，可能html5游戏应该也用不到这么复杂的功能。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;总结：&quot;&gt;&lt;a href=&quot;#总结：&quot; class=&quot;headerlink&quot; title=&quot;总结：&quot;&gt;&lt;/a&gt;总结：&lt;/h3&gt;&lt;p&gt;如果要开发html5游戏，之前用过cocos2d-x之类的，没有用过unity开发的，可以用egret。如果要进行大规模商业开发的，也建议用这个，各个功能比较完善，是成熟的产品。&lt;/p&gt;
    
    </summary>
    
    
      <category term="游戏开发" scheme="https://109383670.github.io/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"/>
    
      <category term="html5" scheme="https://109383670.github.io/tags/html5/"/>
    
      <category term="egret" scheme="https://109383670.github.io/tags/egret/"/>
    
      <category term="cccreator" scheme="https://109383670.github.io/tags/cccreator/"/>
    
  </entry>
  
  <entry>
    <title>ios游戏分辨率问题</title>
    <link href="https://109383670.github.io/2017/03/06/ios%E6%B8%B8%E6%88%8F%E5%88%86%E8%BE%A8%E7%8E%87%E9%97%AE%E9%A2%98/"/>
    <id>https://109383670.github.io/2017/03/06/ios游戏分辨率问题/</id>
    <published>2017-03-06T04:48:56.000Z</published>
    <updated>2019-03-09T04:35:02.737Z</updated>
    
    <content type="html"><![CDATA[<p>屏幕分辨率一般指的是屏幕上像素的多少。所谓像素就是屏幕上的最小发光点，Led灯屏幕的一个像素就是一个Led灯。例如：640*960指的就是屏幕的宽和高上分别有640和960个像素。分辨率越高，图像越精细，也就是常说的高清。</p><h2 id="iPhones设备分辨率"><a href="#iPhones设备分辨率" class="headerlink" title="iPhones设备分辨率"></a>iPhones设备分辨率</h2><h3 id="英寸"><a href="#英寸" class="headerlink" title="英寸"></a>英寸</h3><p><img src="https://i.loli.net/2019/03/04/5c7ce79263590.png" alt="1708203-1768998327604e30"></p><h3 id="像素尺寸"><a href="#像素尺寸" class="headerlink" title="像素尺寸"></a>像素尺寸</h3><p><img src="https://i.loli.net/2019/03/04/5c7cedaea14ef.png" alt="1708203-75913098015ba4c2.png"></p><h3 id="尺寸表"><a href="#尺寸表" class="headerlink" title="尺寸表"></a>尺寸表</h3><p><img src="https://i.loli.net/2019/03/04/5c7cedcdcfc1d.png" alt="1708203-9184bee9ba12d3b5.png"></p><h2 id="游戏开发中用到的分辨率"><a href="#游戏开发中用到的分辨率" class="headerlink" title="游戏开发中用到的分辨率"></a>游戏开发中用到的分辨率</h2><h3 id="iPhone"><a href="#iPhone" class="headerlink" title="iPhone:"></a>iPhone:</h3><p><img src="https://i.loli.net/2019/03/04/5c7cf2bc17a7b.png" alt="屏幕快照 2019-03-04 下午5.40.41.png"></p><h3 id="iPad"><a href="#iPad" class="headerlink" title="iPad"></a>iPad</h3><p><img src="https://i.loli.net/2019/03/04/5c7cf66791bbc.png" alt="屏幕快照 2019-03-04 下午5.56.37.png"></p><a id="more"></a><h2 id="为什么适配不同分辨率"><a href="#为什么适配不同分辨率" class="headerlink" title="为什么适配不同分辨率"></a>为什么适配不同分辨率</h2><p>不同的设备有不同的分辨率，为了减少美术设计人员的工作量，统一化产品设计就必须适配各种分辨率。尽量做到一套设计，不同分辨率的设备都可以通用，不需要美术设计人员针对每一个分辨率版本都给出不同的设计方案，也便于维护升级。<br>一套设计也便于减少游戏安装包大小，优化资源，提高游戏运行速度。</p><h2 id="适配分辨率方案"><a href="#适配分辨率方案" class="headerlink" title="适配分辨率方案"></a>适配分辨率方案</h2><h3 id="1、针对不同的分辨率，给出不同的设计。"><a href="#1、针对不同的分辨率，给出不同的设计。" class="headerlink" title="1、针对不同的分辨率，给出不同的设计。"></a>1、针对不同的分辨率，给出不同的设计。</h3><ul><li>优点：<br>效果最好，因为针对每一个分辨率都做了专门的适配，不同的分辨率都能体现最好的设计效果。</li></ul><ul><li>缺点：<br>工作量大，维护困难，每一次升级修改都需要针对每一个分辨率的版本进行更新，大大增加了工作时间和出错的可能性。不利于扩展，如果市场上出现了新的设备，不同的分辨率，又得更新版本升级。</li></ul><h3 id="2、-按实际屏幕大小进行缩放"><a href="#2、-按实际屏幕大小进行缩放" class="headerlink" title="2、 按实际屏幕大小进行缩放"></a>2、 按实际屏幕大小进行缩放</h3><p>针对不同的分辨率，将游戏画面整个进行缩放，填充满整个屏幕。</p><ul><li><p>优点：<br>通用性高，工作量低。不管什么屏幕都是一套素材，一套代码，不需要额外的工作。</p></li><li><p>缺点：<br>画面严重失真，因为是按照实际屏幕进行缩放，所以如果实际屏幕的宽高比与设计的宽高比不同的话，画面就会出现变形。整个画面看起来像是被压扁或是拉长。</p><p>如下图，变形了：<br><img src="https://i.loli.net/2019/03/04/5c7cee40a9aaa.jpg" alt="123.jpg"></p></li></ul><h3 id="3、-按设计比例进行缩放"><a href="#3、-按设计比例进行缩放" class="headerlink" title="3、 按设计比例进行缩放"></a>3、 按设计比例进行缩放</h3><p>针对不同的分辨率，按固定的宽高比进行缩放。</p><ul><li><p>优点：<br>最大程度的还原设计师的设计，可以做到一套设计通用，不会出现失真。</p></li><li><p>缺点：<br>会在屏幕上下或者左右留下黑边，影响游戏体验。</p></li></ul><p>如下图，有黑边，UI位置暴露了：<br><img src="https://i.loli.net/2019/03/04/5c7cee40bc684.jpg" alt="222.jpg"></p><h3 id="4、固定高度适配"><a href="#4、固定高度适配" class="headerlink" title="4、固定高度适配"></a>4、固定高度适配</h3><p>  在3号方案的基础上，对按钮等UI元素根据分辨率进行动态计算调整。</p><ul><li><p>优点<br>一套设计通用，不会出现2、3中的问题。</p></li><li><p>缺点：<br>不能完全的还原设计师设计，要做出妥协。</p></li></ul><h2 id="实际开发中采用的方案"><a href="#实际开发中采用的方案" class="headerlink" title="实际开发中采用的方案"></a>实际开发中采用的方案</h2><p>实际开发中采用的方案是4号方案。4号方案能在保证画面不变形和出现黑边的情况下，最大程度的减少工作量。但是需要设计师巧妙的设计游戏背景图画。</p><p> 以下图为例：<br>正常的设计分辨率：<br><img src="https://i.loli.net/2019/03/04/5c7cee7671a87.jpg" alt="0x0ss.jpg"></p><p>ipad适配后的分辨率：</p><p><img src="https://i.loli.net/2019/03/04/5c7cee76866b0.jpg" alt="0x0ss-2.jpg"></p><h3 id="设计师设计比例"><a href="#设计师设计比例" class="headerlink" title="设计师设计比例"></a>设计师设计比例</h3><p>根据游戏的主要用户和市场上手机的主要分辨率，决定设计师设计游戏UI时使用的分辨率。设计师只需要注意分辨率的宽高比，宽高比决定了屏幕上的布局。设计师作图时，应该根据宽高比，最大化画布的大小。<br>比如：如果设计师的画布大小只有640x1136大小，当一旦需要1242x2208大小的图片时，设计师只能放大图片，这样就会导致图片质量下降。而如果设计师一开始的画布大小是2484x4416时，只需要将导出的图片缩小就可以了，不会过多的影响图片质量。</p><h3 id="实际使用比例"><a href="#实际使用比例" class="headerlink" title="实际使用比例"></a>实际使用比例</h3><p>游戏的主要人群是iPhone用户，而市场上的主流设备是iphone5以上，所以采用的设备宽高比是<strong>0.562</strong>，也就是iphone6的宽高比。</p><h3 id="计算背景图片需要大小："><a href="#计算背景图片需要大小：" class="headerlink" title="计算背景图片需要大小："></a>计算背景图片需要大小：</h3><p>根据要适配的屏幕宽高比，主要有3种：</p><ul><li>iphone 6 : 0.562 </li><li>iphone 4s : 0.667</li><li>ipad：0.75</li></ul><p>假设高度为1，那么这3种分辨率中，宽度最大的是ipad的宽度，为0.75。那么设计师要设计的背景图片的宽高比根据最大宽度原则，采用0.75。</p><h3 id="设计师如何工作"><a href="#设计师如何工作" class="headerlink" title="设计师如何工作"></a>设计师如何工作</h3><p>说明图如下：<br><img src="https://i.loli.net/2019/03/04/5c7cee9dcfd88.png" alt="粘贴图片.png"></p><h4 id="真实的分辨率："><a href="#真实的分辨率：" class="headerlink" title="真实的分辨率："></a>真实的分辨率：</h4><p>750x1334</p><h4 id="背景图片大小："><a href="#背景图片大小：" class="headerlink" title="背景图片大小："></a>背景图片大小：</h4><p>高度 = 1334<br>宽度 = 1002。计算过程：1334x0.75 = 1000.5 。近似取偶数 = <strong>1002</strong><br>最终大小：<strong>1002x1334</strong><br>设计师做图时，可以选择做一个2倍大的背景图。1002x2 = 2004、 1334x2 = 2668。</p><h4 id="设计师设计步骤："><a href="#设计师设计步骤：" class="headerlink" title="设计师设计步骤："></a>设计师设计步骤：</h4><ol><li>新建大小为 <strong>1500x2668</strong>的画布</li><li>安排按钮等UI布局</li><li>设计游戏背景图</li><li>将背景图单独拿出来，扩充为2004x2668大小的画布，将多出来的部分过渡好。</li></ol><p>注意：<br>设计师主要精力放在1500x2668这个画布上，主要的元素都要在这个画布上呈现。背景宽度扩充的部分只需要过渡好，让玩家看起来不突兀，自然就好。</p><p>作品：<br>设计师需要提交1002x1334的背景图，其他的ui元素正常提交，没有变动。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p> <a href="https://www.jianshu.com/p/41a8ccdf91ed" target="_blank" rel="noopener">iPhone屏幕分辨率和适配规则（基础篇）</a><br> <a href="https://help.apple.com/app-store-connect/?lang=zh-cn#/devd274dd925" target="_blank" rel="noopener">iOS app屏幕快照规范</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;屏幕分辨率一般指的是屏幕上像素的多少。所谓像素就是屏幕上的最小发光点，Led灯屏幕的一个像素就是一个Led灯。例如：640*960指的就是屏幕的宽和高上分别有640和960个像素。分辨率越高，图像越精细，也就是常说的高清。&lt;/p&gt;
&lt;h2 id=&quot;iPhones设备分辨率&quot;&gt;&lt;a href=&quot;#iPhones设备分辨率&quot; class=&quot;headerlink&quot; title=&quot;iPhones设备分辨率&quot;&gt;&lt;/a&gt;iPhones设备分辨率&lt;/h2&gt;&lt;h3 id=&quot;英寸&quot;&gt;&lt;a href=&quot;#英寸&quot; class=&quot;headerlink&quot; title=&quot;英寸&quot;&gt;&lt;/a&gt;英寸&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/03/04/5c7ce79263590.png&quot; alt=&quot;1708203-1768998327604e30&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;像素尺寸&quot;&gt;&lt;a href=&quot;#像素尺寸&quot; class=&quot;headerlink&quot; title=&quot;像素尺寸&quot;&gt;&lt;/a&gt;像素尺寸&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/03/04/5c7cedaea14ef.png&quot; alt=&quot;1708203-75913098015ba4c2.png&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;尺寸表&quot;&gt;&lt;a href=&quot;#尺寸表&quot; class=&quot;headerlink&quot; title=&quot;尺寸表&quot;&gt;&lt;/a&gt;尺寸表&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/03/04/5c7cedcdcfc1d.png&quot; alt=&quot;1708203-9184bee9ba12d3b5.png&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;游戏开发中用到的分辨率&quot;&gt;&lt;a href=&quot;#游戏开发中用到的分辨率&quot; class=&quot;headerlink&quot; title=&quot;游戏开发中用到的分辨率&quot;&gt;&lt;/a&gt;游戏开发中用到的分辨率&lt;/h2&gt;&lt;h3 id=&quot;iPhone&quot;&gt;&lt;a href=&quot;#iPhone&quot; class=&quot;headerlink&quot; title=&quot;iPhone:&quot;&gt;&lt;/a&gt;iPhone:&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/03/04/5c7cf2bc17a7b.png&quot; alt=&quot;屏幕快照 2019-03-04 下午5.40.41.png&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;iPad&quot;&gt;&lt;a href=&quot;#iPad&quot; class=&quot;headerlink&quot; title=&quot;iPad&quot;&gt;&lt;/a&gt;iPad&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2019/03/04/5c7cf66791bbc.png&quot; alt=&quot;屏幕快照 2019-03-04 下午5.56.37.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="游戏开发" scheme="https://109383670.github.io/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"/>
    
      <category term="ios" scheme="https://109383670.github.io/tags/ios/"/>
    
  </entry>
  
  <entry>
    <title>Scrapy学习记录</title>
    <link href="https://109383670.github.io/2017/02/27/Scrapy%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
    <id>https://109383670.github.io/2017/02/27/Scrapy学习记录/</id>
    <published>2017-02-27T05:19:50.000Z</published>
    <updated>2017-02-27T14:09:59.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Scrapy-Shell-命令"><a href="#Scrapy-Shell-命令" class="headerlink" title="Scrapy Shell 命令:"></a>Scrapy Shell 命令:</h2><ul><li><p>开始抓取网页:</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell <span class="string">'http://www.dytt8.net/index.htm'</span></span><br></pre></td></tr></table></figure></li><li><p>selector内容:</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response.xpath(<span class="string">"//a/@href"</span>).extract()[<span class="number">0</span>]</span><br></pre></td></tr></table></figure></li><li><p>输出jsonItem：</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl dmoz -o items.json</span><br></pre></td></tr></table></figure></li></ul><h2 id="xpath"><a href="#xpath" class="headerlink" title="xpath:"></a>xpath:</h2><ul><li><p>following-sibling:<br>除自身外后面的同辈兄弟。如：td/following-sibling::td    同级td兄弟。</p></li><li><p>xpath中的序列从1开始：/a[1],代表a的第一个元素。没有[0]。</p></li><li><p>遍历多个变量：</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> t , l <span class="keyword">in</span> izip(response.xpath(strname), response.xpath(strurl)):</span><br></pre></td></tr></table></figure></li><li><p>r<br>在Python的string前面加上‘r’， 是为了告诉编译器这个string是个raw string，不要转意backslash ‘\’ 。 例如，\n 在raw string中，是两个字符，\和n， 而不会转意为换行符。由于正则表达式和 \ 会有冲突，因此，当一个字符串使用了正则表达式后，最好在前面加上’r’。</p></li></ul><h2 id="激活pipeline"><a href="#激活pipeline" class="headerlink" title="激活pipeline:"></a>激活pipeline:</h2><p>在setting.py里，为了启用一个Item Pipeline组件，你必须将它的类添加到 ITEM_PIPELINES 配置，就像下面这个例子:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    &apos;myproject.pipelines.PricePipeline&apos;: 300,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>分配给每个类的整型值，确定了他们运行的顺序，item按数字从低到高的顺序，通过pipeline，通常将这些数字定义在0-1000范围内。如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;&apos;工程名.pipelines.自定义处理pipe类名&apos;: 1&#125;</span><br></pre></td></tr></table></figure><h2 id="使用相对XPaths"><a href="#使用相对XPaths" class="headerlink" title="使用相对XPaths:"></a>使用相对XPaths:</h2><p>/或者//永远表示的是绝对路径，在嵌套xpath里，用’a/text()’这样的相对路径。</p><h2 id="response-urljoin"><a href="#response-urljoin" class="headerlink" title="response.urljoin:"></a>response.urljoin:</h2><p>方法建立绝对路径并且产生新的请求，并注册回调函数parse_dir_contents()来爬取需要的数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">"ul.directory.dir-col &gt; li &gt; a::attr('href')"</span>):</span><br><span class="line">            url = response.urljoin(href.extract())</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url, callback=self.parse_dir_contents)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_dir_contents</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> sel <span class="keyword">in</span> response.xpath(<span class="string">'//ul/li'</span>):</span><br><span class="line">            item = DmozItem()</span><br><span class="line">            item[<span class="string">'title'</span>] = sel.xpath(<span class="string">'a/text()'</span>).extract()</span><br><span class="line">            item[<span class="string">'link'</span>] = sel.xpath(<span class="string">'a/@href'</span>).extract()</span><br><span class="line">            item[<span class="string">'desc'</span>] = sel.xpath(<span class="string">'text()'</span>).extract()</span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="递归抓取"><a href="#递归抓取" class="headerlink" title="递归抓取:"></a>递归抓取:</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Blurb2Spider</span><span class="params">(BaseSpider)</span>:</span></span><br><span class="line">   name = <span class="string">"blurb2"</span></span><br><span class="line">   allowed_domains = [<span class="string">"www.domain.com"</span>]</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">            <span class="keyword">yield</span> self.make_requests_from_url(<span class="string">"http://www.domain.com/bookstore/new"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">       hxs = HtmlXPathSelector(response)</span><br><span class="line">       urls = hxs.select(<span class="string">'//div[@class="bookListingBookTitle"]/a/@href'</span>).extract()</span><br><span class="line">       <span class="keyword">for</span> i <span class="keyword">in</span> urls:</span><br><span class="line">           <span class="keyword">yield</span> Request(urlparse.urljoin(<span class="string">'https://www.domain.com/'</span>, i[<span class="number">1</span>:]),callback=self.parse_url)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">parse_url</span><span class="params">(self, response)</span>:</span></span><br><span class="line">       hxs = HtmlXPathSelector(response)</span><br><span class="line">       <span class="keyword">print</span> response,<span class="string">'-------&gt;'</span></span><br></pre></td></tr></table></figure><h2 id="相对地址"><a href="#相对地址" class="headerlink" title="相对地址:"></a>相对地址:</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urljoin</span><br><span class="line">urlparse.urljoin(response.url, myurl)</span><br></pre></td></tr></table></figure><h2 id="定制图片管道的例子"><a href="#定制图片管道的例子" class="headerlink" title="定制图片管道的例子:"></a>定制图片管道的例子:</h2><p>下面是一个图片管道的完整例子，其方法如上所示:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.pipeline.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"><span class="keyword">from</span> scrapy.exceptions <span class="keyword">import</span> DropItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyImagesPipeline</span><span class="params">(ImagesPipeline)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(self, item, info)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> image_url <span class="keyword">in</span> item[<span class="string">'image_urls'</span>]:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(image_url)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span><span class="params">(self, results, item, info)</span>:</span></span><br><span class="line">        image_paths = [x[<span class="string">'path'</span>] <span class="keyword">for</span> ok, x <span class="keyword">in</span> results <span class="keyword">if</span> ok]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> image_paths:</span><br><span class="line">            <span class="keyword">raise</span> DropItem(<span class="string">"Item contains no images"</span>)</span><br><span class="line">        item[<span class="string">'image_paths'</span>] = image_paths</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure><h2 id="定位要详细"><a href="#定位要详细" class="headerlink" title="定位要详细:"></a>定位要详细:</h2><p>//div[@id = “Zoom”]//img[1]/@src<br>div的定位要详细，如果是<br>//div/span/img[1]/@src<br>就返回为null,虽然firebug里面也没有问题。</p><h2 id="Strip"><a href="#Strip" class="headerlink" title="Strip():"></a>Strip():</h2><p>Python strip() 方法用于移除字符串头尾指定的字符（默认为空格）。<br>MapCompose(unicode.strip, unicode.title))  ，移除空格与换行<br>例如:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">l.add_xpath(<span class="string">'image_time'</span>, <span class="string">'//div[@class = "co_content8"]/ul/text()[1]'</span>, MapCompose(unicode.strip, unicode.title))</span><br></pre></td></tr></table></figure><h2 id="下载图片"><a href="#下载图片" class="headerlink" title="下载图片:"></a>下载图片:</h2><p>settings.py中有一行ROBOTSTXT_OBEY = True，需要改成False，否则可能下载不了图片。<br>ROBOTSTXT_OBEY<br>是否遵守robot协议，有些网站的robot.txt中表明，不允许爬去，这时候，如果要爬去的话，就要设置为false，不遵守。</p><h2 id="No-Moulde-PIL-Find"><a href="#No-Moulde-PIL-Find" class="headerlink" title="No Moulde PIL Find:"></a>No Moulde PIL Find:</h2><p>直接用pycharm自带的interpreter安装pillow</p><h2 id="mac下要注意python的安装路径"><a href="#mac下要注意python的安装路径" class="headerlink" title="mac下要注意python的安装路径"></a>mac下要注意python的安装路径</h2><h2 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h2><blockquote><p><a href="http://www.jianshu.com/p/078ad2067419" target="_blank" rel="noopener">http://www.jianshu.com/p/078ad2067419</a><br><a href="http://www.cnblogs.com/kylinlin/p/5405246.html" target="_blank" rel="noopener">http://www.cnblogs.com/kylinlin/p/5405246.html</a><br><a href="http://wiki.jikexueyuan.com/project/scrapy/item-pipeline.html" target="_blank" rel="noopener">http://wiki.jikexueyuan.com/project/scrapy/item-pipeline.html</a><br><a href="http://www.open-open.com/lib/view/open1432868637316.html" target="_blank" rel="noopener">http://www.open-open.com/lib/view/open1432868637316.html</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Scrapy-Shell-命令&quot;&gt;&lt;a href=&quot;#Scrapy-Shell-命令&quot; class=&quot;headerlink&quot; title=&quot;Scrapy Shell 命令:&quot;&gt;&lt;/a&gt;Scrapy Shell 命令:&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;开始抓取网页:&lt;/p&gt;
  &lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;scrapy shell &lt;span class=&quot;string&quot;&gt;&#39;http://www.dytt8.net/index.htm&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;selector内容:&lt;/p&gt;
  &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;response.xpath(&lt;span class=&quot;string&quot;&gt;&quot;//a/@href&quot;&lt;/span&gt;).extract()[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;]&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;输出jsonItem：&lt;/p&gt;
  &lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;scrapy crawl dmoz -o items.json&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;xpath&quot;&gt;&lt;a href=&quot;#xpath&quot; class=&quot;headerlink&quot; title=&quot;xpath:&quot;&gt;&lt;/a&gt;xpath:&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;following-sibling:&lt;br&gt;除自身外后面的同辈兄弟。如：td/following-sibling::td    同级td兄弟。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;xpath中的序列从1开始：/a[1],代表a的第一个元素。没有[0]。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;遍历多个变量：&lt;/p&gt;
  &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; t , l &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; izip(response.xpath(strname), response.xpath(strurl)):&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;r&lt;br&gt;在Python的string前面加上‘r’， 是为了告诉编译器这个string是个raw string，不要转意backslash ‘\’ 。 例如，\n 在raw string中，是两个字符，\和n， 而不会转意为换行符。由于正则表达式和 \ 会有冲突，因此，当一个字符串使用了正则表达式后，最好在前面加上’r’。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;激活pipeline&quot;&gt;&lt;a href=&quot;#激活pipeline&quot; class=&quot;headerlink&quot; title=&quot;激活pipeline:&quot;&gt;&lt;/a&gt;激活pipeline:&lt;/h2&gt;&lt;p&gt;在setting.py里，为了启用一个Item Pipeline组件，你必须将它的类添加到 ITEM_PIPELINES 配置，就像下面这个例子:&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ITEM_PIPELINES = &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &amp;apos;myproject.pipelines.PricePipeline&amp;apos;: 300,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;分配给每个类的整型值，确定了他们运行的顺序，item按数字从低到高的顺序，通过pipeline，通常将这些数字定义在0-1000范围内。如：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ITEM_PIPELINES = &amp;#123;&amp;apos;工程名.pipelines.自定义处理pipe类名&amp;apos;: 1&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;使用相对XPaths&quot;&gt;&lt;a href=&quot;#使用相对XPaths&quot; class=&quot;headerlink&quot; title=&quot;使用相对XPaths:&quot;&gt;&lt;/a&gt;使用相对XPaths:&lt;/h2&gt;&lt;p&gt;/或者//永远表示的是绝对路径，在嵌套xpath里，用’a/text()’这样的相对路径。&lt;/p&gt;
&lt;h2 id=&quot;response-urljoin&quot;&gt;&lt;a href=&quot;#response-urljoin&quot; class=&quot;headerlink&quot; title=&quot;response.urljoin:&quot;&gt;&lt;/a&gt;response.urljoin:&lt;/h2&gt;&lt;p&gt;方法建立绝对路径并且产生新的请求，并注册回调函数parse_dir_contents()来爬取需要的数据。&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, response)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; href &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; response.css(&lt;span class=&quot;string&quot;&gt;&quot;ul.directory.dir-col &amp;gt; li &amp;gt; a::attr(&#39;href&#39;)&quot;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            url = response.urljoin(href.extract())&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;keyword&quot;&gt;yield&lt;/span&gt; scrapy.Request(url, callback=self.parse_dir_contents)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;parse_dir_contents&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, response)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; sel &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; response.xpath(&lt;span class=&quot;string&quot;&gt;&#39;//ul/li&#39;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            item = DmozItem()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            item[&lt;span class=&quot;string&quot;&gt;&#39;title&#39;&lt;/span&gt;] = sel.xpath(&lt;span class=&quot;string&quot;&gt;&#39;a/text()&#39;&lt;/span&gt;).extract()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            item[&lt;span class=&quot;string&quot;&gt;&#39;link&#39;&lt;/span&gt;] = sel.xpath(&lt;span class=&quot;string&quot;&gt;&#39;a/@href&#39;&lt;/span&gt;).extract()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            item[&lt;span class=&quot;string&quot;&gt;&#39;desc&#39;&lt;/span&gt;] = sel.xpath(&lt;span class=&quot;string&quot;&gt;&#39;text()&#39;&lt;/span&gt;).extract()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;            &lt;span class=&quot;keyword&quot;&gt;yield&lt;/span&gt; item&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Scrapy" scheme="https://109383670.github.io/tags/Scrapy/"/>
    
      <category term="Learning" scheme="https://109383670.github.io/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>Scrapy安装与运行记录</title>
    <link href="https://109383670.github.io/2017/02/27/Scrapy%E5%AE%89%E8%A3%85%E4%B8%8E%E8%BF%90%E8%A1%8C%E8%AE%B0%E5%BD%95/"/>
    <id>https://109383670.github.io/2017/02/27/Scrapy安装与运行记录/</id>
    <published>2017-02-27T04:02:44.000Z</published>
    <updated>2017-02-27T04:50:17.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装Homebrew"><a href="#安装Homebrew" class="headerlink" title="安装Homebrew"></a>安装Homebrew</h2><pre><code>ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;</code></pre><h2 id="安装python"><a href="#安装python" class="headerlink" title="安装python"></a>安装python</h2><pre><code>brew install python</code></pre><p>Homebrew会自动安装好Setuptools和 pip 。<br>Setuptools提供 easy_install 命令，实现通过网络（通常Internet）下载和安装第三方Python包。 还可以轻松地将这种网络安装的方式加入到自己开发的Python应用中。<br>pip 是一款方便安装和管理Python 包的工具。</p><h2 id="安装Scrapy"><a href="#安装Scrapy" class="headerlink" title="安装Scrapy"></a>安装Scrapy</h2><pre><code>pip install scrapy</code></pre><h3 id="Scrapy-使用"><a href="#Scrapy-使用" class="headerlink" title="Scrapy 使用:"></a>Scrapy 使用:</h3><ul><li>IDE工具：pycharm社区免费版本<ul><li>教程参考: <a href="http://scrapy-chs.readthedocs.io/zh_CN/latest/intro/tutorial.html#intro-tutorial" target="_blank" rel="noopener">http://scrapy-chs.readthedocs.io/zh_CN/latest/intro/tutorial.html#intro-tutorial</a> </li></ul></li></ul><h3 id="命令"><a href="#命令" class="headerlink" title="命令:"></a>命令:</h3><ul><li><p>生成HelloWorld的Scrapy工程  </p><pre><code>scrapy startproject HelloWorld  </code></pre></li><li>在pycharm IDE中配置命令<br><img src="/images/A373E711-D1C1-42FB-83BB-772FD44EB369.png" alt="A373E711-D1C1-42FB-83BB-772FD44EB369"></li></ul><h3 id="原理："><a href="#原理：" class="headerlink" title="原理："></a>原理：</h3><p>   执行:</p><pre><code>scrapy crawl MyPa (MyPa是自己在类中定义的爬虫名字)，</code></pre><p>   相当于在终端执行：</p><pre><code>/usr/local/bin/python /usr/local/lib/python2.7/site-packages/scrapy/cmdline.py crawl MyPa</code></pre><p> 注意：要小心python的路径，如果python的路径不对，还是会报错。这里指的路径是系统路径与pycharm里设置的python路径。<br>            在终端里用which python查看一下路径,如果与pycharm设置里的不同，将修改成更系统路径一样的。</p><h2 id="中文问题"><a href="#中文问题" class="headerlink" title="中文问题:"></a>中文问题:</h2><ul><li>shell里输出的是utf-8编码,用print可打印出中文。</li><li>用变量格式化的方式，不直接在xpath中用中文字符，而是用一个变量代替。如’中文’,用u’中文’。或者在字符串前加u。如u”//a/text()”</li><li><p>打印的时候可以参考：</p> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> sel <span class="keyword">in</span>  response.xpath(<span class="string">"//div[@id='mcontent']/div/p"</span>):</span><br><span class="line">      conect = sel.xpath(<span class="string">"text()"</span>).extract()</span><br><span class="line">         <span class="keyword">for</span> t <span class="keyword">in</span> conect:</span><br><span class="line">           print(t.encode(<span class="string">"utf-8"</span>))</span><br></pre></td></tr></table></figure></li><li><p>pycharm中支持中文</p><ol><li><p>代码页加入:</p><p> <code># -*-coding:utf-8-*-</code></p></li><li><p>代码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">strpath = <span class="string">u"//td[descendant::a[contains(text(),'中文字符')]]"</span>。</span><br><span class="line">或者</span><br><span class="line">strz = <span class="string">'中文字符'</span></span><br><span class="line">strpath = <span class="string">u"//td[descendant::a[contains(text(),%s)]]%strz"</span></span><br></pre></td></tr></table></figure></li></ol></li><li><p>json输出中文：</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.file = codecs.open(<span class="string">"items.json"</span>, <span class="string">"wb"</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">    line = json.dumps(dict(item), ensure_ascii=<span class="literal">False</span>) + <span class="string">"\n"</span></span><br><span class="line">    self.file.write(line)</span><br><span class="line">    <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spider_closed</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">    self.file.close()</span><br></pre></td></tr></table></figure><a id="more"></a></li></ul><p>##读取文件<br>with codecs.open(file_name, “r”,encoding=’utf-8’, errors=’ignore’) as fdata:</p><p>##decode encode<br>decode 总是返回unicode字符<br>encode 总是接受一个unicode字符进行转换</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;安装Homebrew&quot;&gt;&lt;a href=&quot;#安装Homebrew&quot; class=&quot;headerlink&quot; title=&quot;安装Homebrew&quot;&gt;&lt;/a&gt;安装Homebrew&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;ruby -e &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;安装python&quot;&gt;&lt;a href=&quot;#安装python&quot; class=&quot;headerlink&quot; title=&quot;安装python&quot;&gt;&lt;/a&gt;安装python&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;brew install python
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Homebrew会自动安装好Setuptools和 pip 。&lt;br&gt;Setuptools提供 easy_install 命令，实现通过网络（通常Internet）下载和安装第三方Python包。 还可以轻松地将这种网络安装的方式加入到自己开发的Python应用中。&lt;br&gt;pip 是一款方便安装和管理Python 包的工具。&lt;/p&gt;
&lt;h2 id=&quot;安装Scrapy&quot;&gt;&lt;a href=&quot;#安装Scrapy&quot; class=&quot;headerlink&quot; title=&quot;安装Scrapy&quot;&gt;&lt;/a&gt;安装Scrapy&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;pip install scrapy
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;Scrapy-使用&quot;&gt;&lt;a href=&quot;#Scrapy-使用&quot; class=&quot;headerlink&quot; title=&quot;Scrapy 使用:&quot;&gt;&lt;/a&gt;Scrapy 使用:&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;IDE工具：pycharm社区免费版本&lt;ul&gt;
&lt;li&gt;教程参考: &lt;a href=&quot;http://scrapy-chs.readthedocs.io/zh_CN/latest/intro/tutorial.html#intro-tutorial&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://scrapy-chs.readthedocs.io/zh_CN/latest/intro/tutorial.html#intro-tutorial&lt;/a&gt; &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;命令&quot;&gt;&lt;a href=&quot;#命令&quot; class=&quot;headerlink&quot; title=&quot;命令:&quot;&gt;&lt;/a&gt;命令:&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;生成HelloWorld的Scrapy工程  &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scrapy startproject HelloWorld  
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;在pycharm IDE中配置命令&lt;br&gt;&lt;img src=&quot;/images/A373E711-D1C1-42FB-83BB-772FD44EB369.png&quot; alt=&quot;A373E711-D1C1-42FB-83BB-772FD44EB369&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;原理：&quot;&gt;&lt;a href=&quot;#原理：&quot; class=&quot;headerlink&quot; title=&quot;原理：&quot;&gt;&lt;/a&gt;原理：&lt;/h3&gt;&lt;p&gt;   执行:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scrapy crawl MyPa (MyPa是自己在类中定义的爬虫名字)，
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;   相当于在终端执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/usr/local/bin/python /usr/local/lib/python2.7/site-packages/scrapy/cmdline.py crawl MyPa
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt; 注意：要小心python的路径，如果python的路径不对，还是会报错。这里指的路径是系统路径与pycharm里设置的python路径。&lt;br&gt;            在终端里用which python查看一下路径,如果与pycharm设置里的不同，将修改成更系统路径一样的。&lt;/p&gt;
&lt;h2 id=&quot;中文问题&quot;&gt;&lt;a href=&quot;#中文问题&quot; class=&quot;headerlink&quot; title=&quot;中文问题:&quot;&gt;&lt;/a&gt;中文问题:&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;shell里输出的是utf-8编码,用print可打印出中文。&lt;/li&gt;
&lt;li&gt;用变量格式化的方式，不直接在xpath中用中文字符，而是用一个变量代替。如’中文’,用u’中文’。或者在字符串前加u。如u”//a/text()”&lt;/li&gt;
&lt;li&gt;&lt;p&gt;打印的时候可以参考：&lt;/p&gt;
 &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; sel &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt;  response.xpath(&lt;span class=&quot;string&quot;&gt;&quot;//div[@id=&#39;mcontent&#39;]/div/p&quot;&lt;/span&gt;):&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      conect = sel.xpath(&lt;span class=&quot;string&quot;&gt;&quot;text()&quot;&lt;/span&gt;).extract()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;         &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; t &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; conect:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;           print(t.encode(&lt;span class=&quot;string&quot;&gt;&quot;utf-8&quot;&lt;/span&gt;))&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;pycharm中支持中文&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;代码页加入:&lt;/p&gt;
&lt;p&gt; &lt;code&gt;# -*-coding:utf-8-*-&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;代码:&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;strpath = &lt;span class=&quot;string&quot;&gt;u&quot;//td[descendant::a[contains(text(),&#39;中文字符&#39;)]]&quot;&lt;/span&gt;。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;或者&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;strz = &lt;span class=&quot;string&quot;&gt;&#39;中文字符&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;strpath = &lt;span class=&quot;string&quot;&gt;u&quot;//td[descendant::a[contains(text(),%s)]]%strz&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;json输出中文：&lt;/p&gt;
  &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    self.file = codecs.open(&lt;span class=&quot;string&quot;&gt;&quot;items.json&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;wb&quot;&lt;/span&gt;, encoding=&lt;span class=&quot;string&quot;&gt;&quot;utf-8&quot;&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;process_item&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, item, spider)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    line = json.dumps(dict(item), ensure_ascii=&lt;span class=&quot;literal&quot;&gt;False&lt;/span&gt;) + &lt;span class=&quot;string&quot;&gt;&quot;\n&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    self.file.write(line)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; item&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;spider_closed&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(self, spider)&lt;/span&gt;:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    self.file.close()&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="Scrapy" scheme="https://109383670.github.io/tags/Scrapy/"/>
    
      <category term="Setup" scheme="https://109383670.github.io/tags/Setup/"/>
    
  </entry>
  
  <entry>
    <title>hex+mac安装记录</title>
    <link href="https://109383670.github.io/2017/02/22/hex+mac%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/"/>
    <id>https://109383670.github.io/2017/02/22/hex+mac安装记录/</id>
    <published>2017-02-22T12:06:47.000Z</published>
    <updated>2019-04-03T10:30:23.966Z</updated>
    
    <content type="html"><![CDATA[<h2 id="有用的命令-hexo所在目录-："><a href="#有用的命令-hexo所在目录-：" class="headerlink" title="有用的命令(hexo所在目录)："></a>有用的命令(hexo所在目录)：</h2><ul><li>sudo hexo clean -清除</li><li>sudo hexo g -d  直接发布部署</li><li>sudo hexo g  生成   </li><li>sudo hexo s   打开本地服务器   <a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a> 浏览</li></ul><h3 id="本地预览步骤："><a href="#本地预览步骤：" class="headerlink" title="本地预览步骤："></a>本地预览步骤：</h3><ol><li>sudo hexo g</li><li>sudo hexo s</li><li><a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a></li></ol><h2 id="安装参考："><a href="#安装参考：" class="headerlink" title="安装参考："></a>安装参考：</h2><p><a href="https://my.oschina.net/ryaneLee/blog/638440" target="_blank" rel="noopener">参考域名绑定部分、修改主题</a><br><a href="https://my.oschina.net/ryaneLee/blog/638440" target="_blank" rel="noopener">各种出现的问题总结</a> </p><h2 id="hexo更新"><a href="#hexo更新" class="headerlink" title="hexo更新"></a>hexo更新</h2><p><a href="http://www.starlin.top/2018/08/24/更新Hexo版本和Next主题/" target="_blank" rel="noopener">更新Hexo版本和Next主题</a><br><a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">hexo官网</a></p><h2 id="具体安装时出现的问题："><a href="#具体安装时出现的问题：" class="headerlink" title="具体安装时出现的问题："></a>具体安装时出现的问题：</h2><h3 id="不能执行hexo命令"><a href="#不能执行hexo命令" class="headerlink" title="不能执行hexo命令"></a>不能执行hexo命令</h3><p>只有init,help,version三个命令。解决方案：要在hexo目录下执行。</p><h3 id="注意坑：执行hexo-server时出错"><a href="#注意坑：执行hexo-server时出错" class="headerlink" title="注意坑：执行hexo server时出错"></a>注意坑：执行hexo server时出错</h3><p>_config.xml里，type: repo: branch:后面，要有一个空格。</p><h3 id="在DNS的配置里，加入固定的两个IP"><a href="#在DNS的配置里，加入固定的两个IP" class="headerlink" title="在DNS的配置里，加入固定的两个IP"></a>在DNS的配置里，加入固定的两个IP</h3><blockquote><p>@        A        192.30.252.153<br>@        A        192.30.252.154</p></blockquote><h3 id="不能连接git，提示22端口错误"><a href="#不能连接git，提示22端口错误" class="headerlink" title="不能连接git，提示22端口错误"></a>不能连接git，提示22端口错误</h3><p>git网站中的ssh证书失效，要重新生成，参考帮助说明。<br><a href="https://help.github.com/articles/connecting-to-github-with-ssh/" target="_blank" rel="noopener">ssh生成</a><br><a id="more"></a></p><h3 id="git证书生成时，不能填写passphrase这个东西，自己回车跳过"><a href="#git证书生成时，不能填写passphrase这个东西，自己回车跳过" class="headerlink" title="git证书生成时，不能填写passphrase这个东西，自己回车跳过"></a>git证书生成时，不能填写passphrase这个东西，自己回车跳过</h3><h3 id="git-github-com-Permission-denied"><a href="#git-github-com-Permission-denied" class="headerlink" title="git@github.com: Permission denied"></a><a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a>: Permission denied</h3><p>每过一段时间不用，就会出现这个错误。<br>经过测试发现，是因为更换了路由器造成的，可能ip的变化导致ssh密匙的拒绝。</p><h2 id="其他："><a href="#其他：" class="headerlink" title="其他："></a>其他：</h2><p><a href="https://github.com/iissnan/hexo-theme-next" target="_blank" rel="noopener">Next风格不错</a><br><a href="https://github.com/iissnan/hexo-theme-next/wiki" target="_blank" rel="noopener">Next的设置GitWiki里很详细</a><br><a href="http://prozhuchen.com/2015/10/05/Hexo博客之改字体/" target="_blank" rel="noopener">字体及字体大小修改</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;有用的命令-hexo所在目录-：&quot;&gt;&lt;a href=&quot;#有用的命令-hexo所在目录-：&quot; class=&quot;headerlink&quot; title=&quot;有用的命令(hexo所在目录)：&quot;&gt;&lt;/a&gt;有用的命令(hexo所在目录)：&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;sudo hexo clean -清除&lt;/li&gt;
&lt;li&gt;sudo hexo g -d  直接发布部署&lt;/li&gt;
&lt;li&gt;sudo hexo g  生成   &lt;/li&gt;
&lt;li&gt;sudo hexo s   打开本地服务器   &lt;a href=&quot;http://localhost:4000/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://localhost:4000/&lt;/a&gt; 浏览&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;本地预览步骤：&quot;&gt;&lt;a href=&quot;#本地预览步骤：&quot; class=&quot;headerlink&quot; title=&quot;本地预览步骤：&quot;&gt;&lt;/a&gt;本地预览步骤：&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;sudo hexo g&lt;/li&gt;
&lt;li&gt;sudo hexo s&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://localhost:4000/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://localhost:4000/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;安装参考：&quot;&gt;&lt;a href=&quot;#安装参考：&quot; class=&quot;headerlink&quot; title=&quot;安装参考：&quot;&gt;&lt;/a&gt;安装参考：&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://my.oschina.net/ryaneLee/blog/638440&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考域名绑定部分、修改主题&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://my.oschina.net/ryaneLee/blog/638440&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;各种出现的问题总结&lt;/a&gt; &lt;/p&gt;
&lt;h2 id=&quot;hexo更新&quot;&gt;&lt;a href=&quot;#hexo更新&quot; class=&quot;headerlink&quot; title=&quot;hexo更新&quot;&gt;&lt;/a&gt;hexo更新&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;http://www.starlin.top/2018/08/24/更新Hexo版本和Next主题/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;更新Hexo版本和Next主题&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://hexo.io/zh-cn/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;hexo官网&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;具体安装时出现的问题：&quot;&gt;&lt;a href=&quot;#具体安装时出现的问题：&quot; class=&quot;headerlink&quot; title=&quot;具体安装时出现的问题：&quot;&gt;&lt;/a&gt;具体安装时出现的问题：&lt;/h2&gt;&lt;h3 id=&quot;不能执行hexo命令&quot;&gt;&lt;a href=&quot;#不能执行hexo命令&quot; class=&quot;headerlink&quot; title=&quot;不能执行hexo命令&quot;&gt;&lt;/a&gt;不能执行hexo命令&lt;/h3&gt;&lt;p&gt;只有init,help,version三个命令。解决方案：要在hexo目录下执行。&lt;/p&gt;
&lt;h3 id=&quot;注意坑：执行hexo-server时出错&quot;&gt;&lt;a href=&quot;#注意坑：执行hexo-server时出错&quot; class=&quot;headerlink&quot; title=&quot;注意坑：执行hexo server时出错&quot;&gt;&lt;/a&gt;注意坑：执行hexo server时出错&lt;/h3&gt;&lt;p&gt;_config.xml里，type: repo: branch:后面，要有一个空格。&lt;/p&gt;
&lt;h3 id=&quot;在DNS的配置里，加入固定的两个IP&quot;&gt;&lt;a href=&quot;#在DNS的配置里，加入固定的两个IP&quot; class=&quot;headerlink&quot; title=&quot;在DNS的配置里，加入固定的两个IP&quot;&gt;&lt;/a&gt;在DNS的配置里，加入固定的两个IP&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;@        A        192.30.252.153&lt;br&gt;@        A        192.30.252.154&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;不能连接git，提示22端口错误&quot;&gt;&lt;a href=&quot;#不能连接git，提示22端口错误&quot; class=&quot;headerlink&quot; title=&quot;不能连接git，提示22端口错误&quot;&gt;&lt;/a&gt;不能连接git，提示22端口错误&lt;/h3&gt;&lt;p&gt;git网站中的ssh证书失效，要重新生成，参考帮助说明。&lt;br&gt;&lt;a href=&quot;https://help.github.com/articles/connecting-to-github-with-ssh/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ssh生成&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="hexo" scheme="https://109383670.github.io/tags/hexo/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://109383670.github.io/2017/02/22/hello-world/"/>
    <id>https://109383670.github.io/2017/02/22/hello-world/</id>
    <published>2017-02-22T04:41:28.000Z</published>
    <updated>2017-02-22T04:42:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
